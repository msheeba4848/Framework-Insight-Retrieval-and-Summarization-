{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b649d1b-72f0-4ae8-a6f9-6aa075a02757",
   "metadata": {},
   "source": [
    "## 1. Setup and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778e1947-6ba0-4285-bb46-f29f67ee2665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.38.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70123639-f78d-4b13-8eac-0cebaf83d20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 03:29:00.710515: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5019c169-8036-4437-ad55-8c2a77af84e6",
   "metadata": {},
   "source": [
    "## 2. Load Metadata and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdd09364-f8d8-4f69-8be4-67cd9741e71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3777 metadata entries.\n"
     ]
    }
   ],
   "source": [
    "metadata_file = \"metadata_new.json\"\n",
    "\n",
    "def load_metadata(file_path):\n",
    "    \"\"\"Load metadata from a JSON file.\"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "metadata = load_metadata(metadata_file)\n",
    "print(f\"Loaded {len(metadata)} metadata entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c8f2e12-b337-44e2-87c6-1e8930ab796a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text: DAWSON, District Judge.\n",
      "Petitioner, by his guardian, ad litem, sets forth that he is unlawfully restrained of his liberty by Lieutenant Commander J. S. Newell, naval officer in charge at this station,\n"
     ]
    }
   ],
   "source": [
    "# Extract texts for TF-IDF\n",
    "texts = [item['text'] for item in metadata]\n",
    "print(f\"Sample text: {texts[0][:200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2372b65-df98-4e91-8f37-510bc045a9f6",
   "metadata": {},
   "source": [
    "## 3. Generate TF-IDF Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1a76177-90f1-42df-b066-54189a6c6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f933f894-a29d-45b3-9b77-fe34fb7e0566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (3777, 9787)\n"
     ]
    }
   ],
   "source": [
    "tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605a78c7-b728-4dbc-9604-00c36a8cf4e8",
   "metadata": {},
   "source": [
    "## 4. Query with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1115f625-be57-4954-81a3-05d052094d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_query(query, top_k=5):\n",
    "    \"\"\"\n",
    "    Perform a query using TF-IDF and return top-k results.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query text.\n",
    "        top_k (int): Number of top results to return.\n",
    "\n",
    "    Returns:\n",
    "        list: Top-k results with metadata and scores.\n",
    "    \"\"\"\n",
    "    # Transform the query to match the TF-IDF matrix\n",
    "    query_vector = vectorizer.transform([query])\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    scores = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "\n",
    "    # Sort scores in descending order and get top-k indices\n",
    "    top_indices = scores.argsort()[-top_k:][::-1]\n",
    "    \n",
    "    # Gather top-k results\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            \"file\": metadata[idx][\"file\"],\n",
    "            \"text_snippet\": metadata[idx][\"text\"][:200],  # First 200 characters\n",
    "            \"score\": scores[idx]\n",
    "        })\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834a3e20-163e-4845-9573-57aed3462a06",
   "metadata": {},
   "source": [
    "## 5. Summarization with T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d980cdca-c17d-4e8f-a2ad-436d78a89d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934b01b67cd34817821b6143b0c32f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75fac4e30684532a883667d60a5f177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2590e96bc9a846b3904d7228a2fc441e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9d01058384482b94dfe21e40843259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4ff8dca59141c1ac62d7eb73991852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01cf986b3b2d4f44af368ced6b259fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t5_model_name = \"t5-small\"  # Use \"t5-base\" or \"t5-large\" for larger models\n",
    "tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(t5_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d68685e-b20e-40c6-a174-f2d2cb884166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(query, results):\n",
    "    \"\"\"\n",
    "    Generate a summary for the query based on top results using T5.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query.\n",
    "        results (list): Top results from the query function.\n",
    "\n",
    "    Returns:\n",
    "        str: Generated summary.\n",
    "    \"\"\"\n",
    "    # Combine text from top results\n",
    "    context = \" \".join([res[\"text_snippet\"] for res in results])\n",
    "\n",
    "    if not context.strip():\n",
    "        return \"No relevant document content found for summarization.\"\n",
    "\n",
    "    # Prepare input for T5 summarization\n",
    "    input_text = f\"question: {query} context: {context}\"\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs, max_length=150, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bf7978-316e-4049-92a0-34b1efb52b5a",
   "metadata": {},
   "source": [
    "## 6. Interactive Query System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0e5d40c-f4e4-4e97-a047-0fbc992758c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_query():\n",
    "    \"\"\"\n",
    "    Allow the user to enter their own query and return results and a summary.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        print(\"\\n--- TF-IDF Query System ---\")\n",
    "        user_query = input(\"Enter your query (or type 'exit' to quit): \").strip()\n",
    "        \n",
    "        if user_query.lower() == 'exit':\n",
    "            print(\"Exiting the query system. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        # Perform the query\n",
    "        results = tfidf_query(user_query)\n",
    "        \n",
    "        # Display the results\n",
    "        print(\"\\nTop Results:\")\n",
    "        for res in results:\n",
    "            print(f\"File: {res['file']}, Score: {res['score']:.4f}\")\n",
    "            print(f\"Text Snippet: {res['text_snippet']}\\n\")\n",
    "\n",
    "        # Generate a summary for the query\n",
    "        print(\"\\nGenerating summary for the query...\")\n",
    "        summary = generate_summary(user_query, results)\n",
    "        print(\"\\nGenerated Summary:\")\n",
    "        print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "684ccc41-12ee-455a-8e4b-4b146964be5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TF-IDF Query System ---\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or type 'exit' to quit):  healthcare\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Results:\n",
      "File: 0001-01.json, Score: 0.0000\n",
      "Text Snippet: DAWSON, District Judge.\n",
      "Petitioner, by his guardian, ad litem, sets forth that he is unlawfully restrained of his liberty by Lieutenant Commander J. S. Newell, naval officer in charge at this station,\n",
      "\n",
      "File: 0005-01.json, Score: 0.0000\n",
      "Text Snippet:  all of them.\n",
      "Every system of laws must necessarily contain defects, and cases often occur for which the law based on precedents and fixed rules affords no redress. It is in such cases only that equit\n",
      "\n",
      "File: 0005-01.json, Score: 0.0000\n",
      "Text Snippet: f cases where the law affords an ample remedy. Equity must necessarily have a place in every rational system of jurisprudence. It is impossible that any code or system of laws, however minute, should \n",
      "\n",
      "File: 0005-01.json, Score: 0.0000\n",
      "Text Snippet: dy at law. To entitle the plaintiff to relief in equity and invoke remedial relief by injunction, it must be made to appear upon the face of the petition that he cannot redress his supposed grievance \n",
      "\n",
      "File: 0005-01.json, Score: 0.0000\n",
      "Text Snippet: and is now in a safe condition for landing vessels, making them fast, and discharging and receiving their cargoes.\n",
      "As I view this case, there is no question of title involved. The plaintiff cannot cla\n",
      "\n",
      "\n",
      "Generating summary for the query...\n",
      "\n",
      "Generated Summary:\n",
      "DAWSON, District Judge. Petitioner, by his guardian, ad litem, sets forth that he is unlawfully restrained of his liberty\n",
      "\n",
      "--- TF-IDF Query System ---\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query (or type 'exit' to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the query system. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "interactive_query()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
