{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b649d1b-72f0-4ae8-a6f9-6aa075a02757",
   "metadata": {},
   "source": [
    "## 1. Setup and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778e1947-6ba0-4285-bb46-f29f67ee2665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.38.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70123639-f78d-4b13-8eac-0cebaf83d20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 08:34:10.049851: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5019c169-8036-4437-ad55-8c2a77af84e6",
   "metadata": {},
   "source": [
    "## 2. Load Metadata and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd09364-f8d8-4f69-8be4-67cd9741e71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3777 metadata entries.\n"
     ]
    }
   ],
   "source": [
    "metadata_file = \"metadata_new.json\"\n",
    "\n",
    "def load_metadata(file_path):\n",
    "    \"\"\"Load metadata from a JSON file.\"\"\"\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "metadata = load_metadata(metadata_file)\n",
    "print(f\"Loaded {len(metadata)} metadata entries.\")\n",
    "\n",
    "## Code review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c8f2e12-b337-44e2-87c6-1e8930ab796a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text: DAWSON, District Judge.\n",
      "Petitioner, by his guardian, ad litem, sets forth that he is unlawfully restrained of his liberty by Lieutenant Commander J. S. Newell, naval officer in charge at this station,\n"
     ]
    }
   ],
   "source": [
    "# Extract texts for TF-IDF\n",
    "texts = [item['text'] for item in metadata]\n",
    "print(f\"Sample text: {texts[0][:200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2372b65-df98-4e91-8f37-510bc045a9f6",
   "metadata": {},
   "source": [
    "## 3. Generate TF-IDF Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1a76177-90f1-42df-b066-54189a6c6c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f933f894-a29d-45b3-9b77-fe34fb7e0566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (3777, 9787)\n"
     ]
    }
   ],
   "source": [
    "tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605a78c7-b728-4dbc-9604-00c36a8cf4e8",
   "metadata": {},
   "source": [
    "## 4. Query with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1115f625-be57-4954-81a3-05d052094d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_query(query, top_k=5):\n",
    "    \"\"\"\n",
    "    Perform a query using TF-IDF and return top-k results.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query text.\n",
    "        top_k (int): Number of top results to return.\n",
    "\n",
    "    Returns:\n",
    "        list: Top-k results with metadata and scores.\n",
    "    \"\"\"\n",
    "    # Transform the query to match the TF-IDF matrix\n",
    "    query_vector = vectorizer.transform([query])\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    scores = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "\n",
    "    # Sort scores in descending order and get top-k indices\n",
    "    top_indices = scores.argsort()[-top_k:][::-1]\n",
    "    \n",
    "    # Gather top-k results\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            \"file\": metadata[idx][\"file\"],\n",
    "            \"text_snippet\": metadata[idx][\"text\"][:200],  # First 200 characters\n",
    "            \"score\": scores[idx]\n",
    "        })\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834a3e20-163e-4845-9573-57aed3462a06",
   "metadata": {},
   "source": [
    "## 5. Summarization with T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d980cdca-c17d-4e8f-a2ad-436d78a89d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "t5_model_name = \"t5-small\" \n",
    "tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(t5_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d68685e-b20e-40c6-a174-f2d2cb884166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(query, results):\n",
    "    \"\"\"\n",
    "    Generate a summary for the query based on top results using T5.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query.\n",
    "        results (list): Top results from the query function.\n",
    "\n",
    "    Returns:\n",
    "        str: Generated summary.\n",
    "    \"\"\"\n",
    "    # Combine text from top results\n",
    "    context = \" \".join([res[\"text_snippet\"] for res in results])\n",
    "\n",
    "    if not context.strip():\n",
    "        return \"No relevant document content found for summarization.\"\n",
    "\n",
    "    # Prepare input for T5 summarization\n",
    "    input_text = f\"question: {query} context: {context}\"\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs, max_length=150, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bf7978-316e-4049-92a0-34b1efb52b5a",
   "metadata": {},
   "source": [
    "## 6. Interactive Query System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0e5d40c-f4e4-4e97-a047-0fbc992758c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_query():\n",
    "    \"\"\"\n",
    "    Allow the user to interact using numbered options (1-5) for uniformity.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        print(\"\\n--- TF-IDF Query System ---\")\n",
    "        print(\"Select a query type:\")\n",
    "        print(\"1. Search by Name\")\n",
    "        print(\"2. Search by File Name\")\n",
    "        print(\"3. Search by Decision Date\")\n",
    "        print(\"4. Search by Custom Legal Query\")\n",
    "        print(\"5. Exit\")\n",
    "        \n",
    "        choice = input(\"Enter choice (1-5): \").strip()\n",
    "        query = \"\"\n",
    "\n",
    "        if choice == \"1\":\n",
    "            query = input(\"Enter case name: \").strip()\n",
    "        elif choice == \"2\":\n",
    "            query = input(\"Enter file name: \").strip()\n",
    "        elif choice == \"3\":\n",
    "            query = input(\"Enter decision date (YYYY-MM-DD): \").strip()\n",
    "        elif choice == \"4\":\n",
    "            query = input(\"Enter your query: \").strip()\n",
    "        elif choice == \"5\":\n",
    "            print(\"Exiting the query system. Goodbye!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice. Please try again.\")\n",
    "            continue\n",
    "\n",
    "        # Perform the query\n",
    "        results = tfidf_query(query)\n",
    "        \n",
    "        # Display the results\n",
    "        print(\"\\nTop Results:\")\n",
    "        for res in results:\n",
    "            print(f\"File: {res['file']}, Score: {res['score']:.4f}\")\n",
    "            print(f\"Text Snippet: {res['text_snippet']}\\n\")\n",
    "\n",
    "        # Generate a summary for the query\n",
    "        print(\"\\nGenerating summary for the query...\")\n",
    "        summary = generate_summary(query, results)\n",
    "        print(\"\\nGenerated Summary:\")\n",
    "        print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31feef4b-cef5-4fa1-9986-b32c9d62d9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TF-IDF Query System ---\n",
      "Select a query type:\n",
      "1. Search by Name\n",
      "2. Search by File Name\n",
      "3. Search by Decision Date\n",
      "4. Search by Custom Legal Query\n",
      "5. Exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter choice (1-5):  2\n",
      "Enter file name:  1892-03-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Results:\n",
      "File: 0165-01.json, Score: 0.2378\n",
      "Text Snippet: ference to such findings I am able to find in Hill’s Annotated Codes is found in section 396, p. 412, vol. 1, compilation of 1892, which reads as follows:\n",
      "“The provisions of title 1 of chapter 2, of t\n",
      "\n",
      "File: 0536-01.json, Score: 0.2283\n",
      "Text Snippet: el for the plaintiff cites Nemitz v. Conrad (a case from the Supreme Court of Oregon, decided March 29, 1892) 29 Pac. 548, in support of his contention that by filing the bond for discharge in this ca\n",
      "\n",
      "File: 0070-01.json, Score: 0.2245\n",
      "Text Snippet: tutes of the United States and acts of Congress and the proclamation of the President thereunder.\n",
      "The hearing of said' cáse was set for June 20, 1892, and the usual monition was issued and published a\n",
      "\n",
      "File: 0070-01.json, Score: 0.2191\n",
      "Text Snippet: TRUITT, District Judge.\n",
      "The libel of information in this case was filed by Chas. S. Johnson, United States District Attorney, on the 29th day of April, 1892, in said court, against said steam schooner\n",
      "\n",
      "File: 0664-01.json, Score: 0.1930\n",
      "Text Snippet: rcuit Court of Appeals for the Seventh Circuit October 26, 1892) 4 C. C. A. 403, 54 Fed. 420, 38 L. R. A. 271, while not a case on all fours with the one at bar, has perhaps some of its earmarks. The \n",
      "\n",
      "\n",
      "Generating summary for the query...\n",
      "\n",
      "Generated Summary:\n",
      "October 26, 1892) 4 C. C. A. 403, 54 Fed. 420, 38 L. R. A. 271, while not a case on all fours with the one at bar, has perhaps some of its earmarks\n",
      "\n",
      "--- TF-IDF Query System ---\n",
      "Select a query type:\n",
      "1. Search by Name\n",
      "2. Search by File Name\n",
      "3. Search by Decision Date\n",
      "4. Search by Custom Legal Query\n",
      "5. Exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter choice (1-5):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid choice. Please try again.\n",
      "\n",
      "--- TF-IDF Query System ---\n",
      "Select a query type:\n",
      "1. Search by Name\n",
      "2. Search by File Name\n",
      "3. Search by Decision Date\n",
      "4. Search by Custom Legal Query\n",
      "5. Exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter choice (1-5):  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the query system. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "interactive_query()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
