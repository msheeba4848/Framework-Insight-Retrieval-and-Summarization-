{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f90a304-074b-4274-90e8-e70eccacb113",
   "metadata": {},
   "source": [
    "## 1. Preprocessing and Saving Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ee27799-49c2-46e5-ae93-0f38b7de23e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1494b2d-1ae8-4b33-b138-4ccf37cc4c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Clean and normalize text.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81995c7c-f547-4861-8bc9-6b306d6a79dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_date(date):\n",
    "    \"\"\"Standardize date to YYYY-MM-DD format.\"\"\"\n",
    "    try:\n",
    "        if len(date) == 4:  # Year only\n",
    "            return pd.to_datetime(f\"{date}-01-01\").strftime(\"%Y-%m-%d\")\n",
    "        elif len(date) == 7:  # Year and month\n",
    "            return pd.to_datetime(f\"{date}-01\").strftime(\"%Y-%m-%d\")\n",
    "        else:  # Full date\n",
    "            return pd.to_datetime(date).strftime(\"%Y-%m-%d\")\n",
    "    except Exception:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3065f4b-cdf6-47d7-9b30-109ac6ea04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save_metadata(json_dir, metadata_file):\n",
    "    \"\"\"Preprocess raw JSON files and save metadata for FAISS.\"\"\"\n",
    "    all_data = []\n",
    "    for file_name in os.listdir(json_dir):\n",
    "        if file_name.endswith(\".json\"):\n",
    "            with open(os.path.join(json_dir, file_name), \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                row = {\n",
    "                    \"file\": file_name,\n",
    "                    \"name\": preprocess_text(data.get(\"name\", \"\")),\n",
    "                    \"abbreviation\": preprocess_text(data.get(\"name_abbreviation\", \"\")),\n",
    "                    \"decision_date\": standardize_date(data.get(\"decision_date\", \"\")),\n",
    "                    \"text\": \" \".join(opinion.get(\"text\", \"\") for opinion in data.get(\"casebody\", {}).get(\"opinions\", [])),\n",
    "                }\n",
    "                all_data.append(row)\n",
    "    \n",
    "    # Save processed metadata\n",
    "    with open(metadata_file, \"w\") as f:\n",
    "        json.dump(all_data, f, indent=4)\n",
    "    print(f\"Metadata saved to {metadata_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49001734-d61e-41cd-8d5d-ea36fb9ec02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved to metadata_faiss.json\n"
     ]
    }
   ],
   "source": [
    "json_dir = \"json/\"  # Folder containing raw JSON files\n",
    "metadata_file = \"metadata_faiss.json\"  # Metadata file for FAISS\n",
    "preprocess_and_save_metadata(json_dir, metadata_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43a791f-0551-49c0-b9c3-9c24f7c204eb",
   "metadata": {},
   "source": [
    "## 2. Creating FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09dc5685-be3b-41cf-9cba-126f1475a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "177b00bc-1704-4642-a9a3-14d693829ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(text, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    \"\"\"Generate embeddings for text.\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e9db511-1399-4f6e-a92b-1ff0090f2686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_faiss_index(metadata_file, index_file):\n",
    "    \"\"\"Create a FAISS index from metadata.\"\"\"\n",
    "    with open(metadata_file, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    # Generate embeddings for each text\n",
    "    embeddings = [embed_text(entry[\"text\"]) for entry in metadata]\n",
    "    embeddings = np.vstack(embeddings)  # Combine embeddings into a matrix\n",
    "\n",
    "    # Create and save FAISS index\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings)\n",
    "    faiss.write_index(index, index_file)\n",
    "    print(f\"FAISS index saved to {index_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b8a30d4-57e8-45fc-9472-5a9b756bc543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "2024-12-09 05:33:30.158393: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved to legal_cases_index.faiss\n"
     ]
    }
   ],
   "source": [
    "create_faiss_index(\"metadata_faiss.json\", \"legal_cases_index.faiss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9a94be-7c6a-4564-91d4-5723210bb26e",
   "metadata": {},
   "source": [
    "## 3. Interactive Query System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af2942d4-58ab-40d4-937c-3c9d0af68323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8efbf890-f558-4c04-b36e-c39564de96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_similar(a, b, threshold=0.8):\n",
    "    \"\"\"Check if two strings are similar using SequenceMatcher.\"\"\"\n",
    "    return SequenceMatcher(None, a, b).ratio() > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23460511-05a6-469a-9f97-8423c18a579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(query):\n",
    "    \"\"\"Normalize and preprocess user query.\"\"\"\n",
    "    query = query.lower().strip()\n",
    "    query = re.sub(r\"[^\\w\\s]\", \"\", query)\n",
    "    query = re.sub(r\"\\s+\", \" \", query)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e9059bd-3fff-4560-a525-c00a5f8afefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_index(user_query, index, metadata, k=5):\n",
    "    \"\"\"Query FAISS index and return top results with partial matching.\"\"\"\n",
    "    query_embedding = embed_text(user_query)\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    results = []\n",
    "\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        metadata_entry = metadata[idx]\n",
    "        results.append({\n",
    "            \"rank\": i + 1,\n",
    "            \"file\": metadata_entry.get(\"file\", \"Unknown\"),\n",
    "            \"name\": metadata_entry.get(\"name\", \"Unknown\"),\n",
    "            \"abbreviation\": metadata_entry.get(\"abbreviation\", \"Unknown\"),\n",
    "            \"text\": metadata_entry.get(\"text\", \"No text available\"),\n",
    "            \"distance\": float(distances[0][i]),\n",
    "        })\n",
    "\n",
    "    # partial matching from metadata\n",
    "    partial_matches = []\n",
    "    for entry in metadata:\n",
    "        name = entry.get(\"name\", \"\").lower()\n",
    "        abbreviation = entry.get(\"abbreviation\", \"\").lower()\n",
    "        if user_query in name or user_query in abbreviation or is_similar(user_query, name) or is_similar(user_query, abbreviation):\n",
    "            partial_matches.append({\n",
    "                \"rank\": \"Partial\",\n",
    "                \"file\": entry.get(\"file\", \"Unknown\"),\n",
    "                \"name\": entry.get(\"name\", \"Unknown\"),\n",
    "                \"abbreviation\": entry.get(\"abbreviation\", \"Unknown\"),\n",
    "                \"text\": entry.get(\"text\", \"No text available\"),\n",
    "                \"distance\": \"N/A\",\n",
    "            })\n",
    "\n",
    "    return results + partial_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10375304-2687-475e-911a-c878f881fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(query, context, model_name=\"facebook/bart-large-cnn\"):\n",
    "    \"\"\"Summarize context using BART.\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    inputs = tokenizer(f\"Query: {query} Context: {context}\", return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    summary_ids = model.generate(inputs.input_ids, max_length=200, min_length=50, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa3e9a0d-499e-47e5-93d5-eda6c349ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_system(index, metadata):\n",
    "    \"\"\"Interactive query system for retrieving legal cases.\"\"\"\n",
    "    print(\"Welcome to the Enhanced Legal Case Retrieval System!\")\n",
    "    print(\"Type 'exit' at any point to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        # Loop until a valid choice is entered\n",
    "        while True:\n",
    "            print(\"Select a query type:\")\n",
    "            print(\"1. Search by Name\")\n",
    "            print(\"2. Search by Abbreviation\")\n",
    "            print(\"3. Search by Decision Date (YYYY-MM-DD): \")\n",
    "            print(\"4. Search by Jurisdiction\")\n",
    "            print(\"5. Custom Query\")\n",
    "            choice = input(\"Enter choice (1-5): \").strip()\n",
    "\n",
    "            if choice.lower() == \"exit\":\n",
    "                print(\"Exiting the system. Goodbye!\")\n",
    "                return  # Exit the function entirely\n",
    "\n",
    "            if choice in {\"1\", \"2\", \"3\", \"4\", \"5\"}:  # Valid choices\n",
    "                break  # Exit the validation loop\n",
    "            else:\n",
    "                print(\"Invalid choice. Please enter a number between 1 and 5.\")\n",
    "\n",
    "        query = input(\"Enter your query: \").strip()\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Exiting the system. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        query = preprocess_query(query)\n",
    "        results = query_index(query, index, metadata)\n",
    "\n",
    "        print(\"\\nRetrieved Results:\")\n",
    "        for result in results:\n",
    "            print(f\"Rank: {result['rank']} - File: {result['file']} - Distance: {result['distance']}\")\n",
    "            print(f\"Name: {result['name']}, Abbreviation: {result['abbreviation']}\")\n",
    "            print(f\"Text Snippet: {result['text'][:200]}...\\n\")\n",
    "\n",
    "        print(\"\\nGenerating summary...\")\n",
    "        context = \" \".join([result[\"text\"] for result in results])\n",
    "        summary = generate_summary(query, context)\n",
    "        print(f\"\\nSummary:\\n{summary}\")\n",
    "\n",
    "        print(\"\\nWould you like to perform another query?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4c11649-039f-41b2-b793-971b60f80810",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(\"legal_cases_index.faiss\")\n",
    "with open(\"metadata_faiss.json\", \"r\") as f:\n",
    "    metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "243003cf-acb7-4cfc-ae0c-72806c88446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Enhanced Legal Case Retrieval System!\n",
      "Type 'exit' at any point to quit.\n",
      "\n",
      "Select a query type:\n",
      "1. Search by Name\n",
      "2. Search by Abbreviation\n",
      "3. Search by Decision Date (YYYY-MM-DD): \n",
      "4. Search by Jurisdiction\n",
      "5. Custom Query\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter choice (1-5):  3\n",
      "Enter your query:  1807-10-16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved Results:\n",
      "Rank: 1 - File: 0104-01.json - Distance: 50.14529037475586\n",
      "Name: moody v the first bank of skagway, Abbreviation: moody v first bank of skagway\n",
      "Text Snippet: BROWN, District Judge.\n",
      "It seems,that the matter now before the court had its origin in the Commissioner’s Court, before C. A. Sehlbrede, United States Commissioner, on the nth day of March, 1899, in A...\n",
      "\n",
      "Rank: 2 - File: 0439-01.json - Distance: 50.163719177246094\n",
      "Name: the tyee consol min co v langstedt et al, Abbreviation: tyee consol min co v langstedt\n",
      "Text Snippet: BROWN, District Judge.\n",
      "In this case, and other cases involving practically the same question, there are about no defendants. The plaintiff is a foreign corporation that has complied with all the laws ...\n",
      "\n",
      "Rank: 3 - File: 0361-01.json - Distance: 50.41318893432617\n",
      "Name: brace v solner treasurer of nome, Abbreviation: brace v solner\n",
      "Text Snippet: WICKERSHAM, District Judge.\n",
      "In a former action this court had occasion to pass upon the power of the council to expend this fund in payment of salaries to the town clerk and treasurer, and in denying ...\n",
      "\n",
      "Rank: 4 - File: 0598-01.json - Distance: 50.42202377319336\n",
      "Name: ames v kruzner et al, Abbreviation: ames v kruzner\n",
      "Text Snippet: WICKERSHAM, District Judge.\n",
      "On October 16, 1900, the defendants, Kruzner and Woodruff, at Nome, made and delivered their promissory note in the sum of $1,514.90 to the Ames Mercantile Company, a forei...\n",
      "\n",
      "Rank: 5 - File: 0561-01.json - Distance: 50.568641662597656\n",
      "Name: black v teeter et al, Abbreviation: black v teeter\n",
      "Text Snippet: W1CKERSHAM, District Judge.\n",
      "A verdict for the plaintiff was rendered by the jury in this case, and the matter now comes up on defendants’ motion for a new trial. The motion contains seven distinct gro...\n",
      "\n",
      "\n",
      "Generating summary...\n",
      "\n",
      "Summary:\n",
      "The suit was brought against the First National Bank of Skagway and C. S. Moody, manager of the Bank. It was alleged that the defendant was indebted to plaintiff in the sum of $211.15 and interest, upon contract for the payment of money. An attachment was issued some time in March but bears no date whatever.\n",
      "\n",
      "Would you like to perform another query?\n",
      "Select a query type:\n",
      "1. Search by Name\n",
      "2. Search by Abbreviation\n",
      "3. Search by Decision Date (YYYY-MM-DD): \n",
      "4. Search by Jurisdiction\n",
      "5. Custom Query\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter choice (1-5):  5\n",
      "Enter your query:  What about Colbert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved Results:\n",
      "Rank: 1 - File: 0217-01.json - Distance: 43.98239517211914\n",
      "Name: united states v alaska packers assn and babler, Abbreviation: united states v alaska packers assn\n",
      "Text Snippet: BROWN, District Judge\n",
      "(orally). In the case of the United States v. The Alaska Packers’ Association and J. Babler, an indictment has been returned by the grand jury, which, omitting the formal parts, ...\n",
      "\n",
      "Rank: 2 - File: 0630-01.json - Distance: 44.141876220703125\n",
      "Name: in re c e wynnjohnson, Abbreviation: in re wynnjohnson\n",
      "Text Snippet: BROWN, District Judge.\n",
      "At the Skagway October, 1901, term of the court, one C. E. Wynn-Johnson and the Moore’s Wharf Company were jointly indicted, under sections 460 and 461 of the crimes act of the ...\n",
      "\n",
      "Rank: 3 - File: 0553-01.json - Distance: 44.245384216308594\n",
      "Name: united states v binns, Abbreviation: united states v binns\n",
      "Text Snippet: WICKERSHAM, District Judge.\n",
      "The defendant was found guilty, and condemned to pay a fine and costs in the justice’s court for violating section 29 of the act of Congress entitled “An act making further...\n",
      "\n",
      "Rank: 4 - File: 0111-01.json - Distance: 44.29438781738281\n",
      "Name: in re burton, Abbreviation: in re burton\n",
      "Text Snippet: BROWN, District Judge.\n",
      "The petition of Samuel Burton states that he is a native of British Columbia, now and for many years a resident of Alaska, and he prays to be admitted to citizenship in the Unit...\n",
      "\n",
      "Rank: 5 - File: 0208-01.json - Distance: 44.36677551269531\n",
      "Name: bates v mayor and council of nome, Abbreviation: bates v mayor of nome\n",
      "Text Snippet: WICKERSHAM, District Judge.\n",
      "The first question urged in the argument of the demurrer, though not specially raised by the demurrer itself, was that the plaintiff had no legal capacity to sue and mainta...\n",
      "\n",
      "\n",
      "Generating summary...\n",
      "\n",
      "Summary:\n",
      "A corporation cannot be imprisoned or hanged, but a corporation can be fined just as a natural person can. If, in the course of its-business, it kill a person, then if the law fix a fine or damages for such unlawful killing, even though it were a felony, the law could be enforced for the payment of such fine, and the property of the corporation made to answer. There are a few old cases that go to the law, but all the more modern cases are the other modern.\n",
      "\n",
      "Would you like to perform another query?\n",
      "Select a query type:\n",
      "1. Search by Name\n",
      "2. Search by Abbreviation\n",
      "3. Search by Decision Date (YYYY-MM-DD): \n",
      "4. Search by Jurisdiction\n",
      "5. Custom Query\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter choice (1-5):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the system. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "query_system(index, metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
