{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c26c951b-c06c-48c4-b1c9-e9f385558f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install \n",
    "#!pip install torch transformers llama-index scikit-learn numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec160237-8bc0-4a3d-ab5d-9b946dd4b9ad",
   "metadata": {},
   "source": [
    "## Load Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dfe5abd-6206-4990-a075-2defe23a1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd20e245-40d1-45f5-b739-4a579a781626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved at: data/output_cases.csv\n"
     ]
    }
   ],
   "source": [
    "# json to csv for data exploration\n",
    "\n",
    "def json_to_csv(json_dir, output_csv):\n",
    "    \"\"\"\n",
    "    Converts all JSON files in a directory into a single CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        json_dir (str): Path to the directory containing JSON files.\n",
    "        output_csv (str): Path to save the output CSV file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    # Iterate over all JSON files in the directory\n",
    "    for file_name in os.listdir(json_dir):\n",
    "        if file_name.endswith(\".json\"):\n",
    "            file_path = os.path.join(json_dir, file_name)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                # Load the JSON data\n",
    "                data = json.load(file)\n",
    "                \n",
    "                # Flatten the JSON structure and extract relevant data\n",
    "                row = {\n",
    "                    \"id\": data.get(\"id\"),\n",
    "                    \"name\": data.get(\"name\"),\n",
    "                    \"abbreviation\": data.get(\"name_abbreviation\"),\n",
    "                    \"decision_date\": data.get(\"decision_date\"),\n",
    "                    \"court_name\": data.get(\"court\", {}).get(\"name\"),\n",
    "                    \"jurisdiction_name\": data.get(\"jurisdiction\", {}).get(\"name\"),\n",
    "                    \"word_count\": data.get(\"analysis\", {}).get(\"word_count\"),\n",
    "                    \"char_count\": data.get(\"analysis\", {}).get(\"char_count\"),\n",
    "                    \"ocr_confidence\": data.get(\"analysis\", {}).get(\"ocr_confidence\"),\n",
    "                    \"case_text\": \" \".join([opinion[\"text\"] for opinion in data.get(\"casebody\", {}).get(\"opinions\", [])]),\n",
    "                }\n",
    "                all_data.append(row)\n",
    "    \n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"CSV file saved at: {output_csv}\")\n",
    "\n",
    "# Specify the path to the JSON directory and output CSV file\n",
    "json_dir = \"json/\"\n",
    "output_csv = \"data/output_cases.csv\"\n",
    "\n",
    "# Convert JSON files to CSV\n",
    "json_to_csv(json_dir, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7fda4fb-63a1-430a-b422-3bf5e150fce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 0001-01.json\n",
      "{\n",
      "    \"id\": 8503986,\n",
      "    \"name\": \"In re JESSE SCOTT OLIVER, Minor\",\n",
      "    \"name_abbreviation\": \"In re Oliver\",\n",
      "    \"decision_date\": \"1887-10-31\",\n",
      "    \"docket_number\": \"No. 95\",\n",
      "    \"first_page\": \"1\",\n",
      "    \"last_page\": \"4\",\n",
      "    \"citations\": [\n",
      "        {\n",
      "            \"type\": \"official\",\n",
      "            \"cite\": \"1 Alaska 1\"\n",
      "        }\n",
      "    ],\n",
      "    \"court\": {\n",
      "        \"name_abbreviation\": \"Alaska Dist. Ct.\",\n",
      "        \"id\": 23837,\n",
      "        \"name\": \"Alaska District Court\"\n",
      "    },\n",
      "    \"jurisdiction\": {\n",
      "        \"id\": 53,\n",
      "        \"name_long\": \"Alaska\",\n",
      "        \"name\": \"Alaska\"\n",
      "    },\n",
      "    \"cites_to\": [\n",
      "        {\n",
      "            \"cite\": \"6 Am. Dec. 156\",\n",
      "            \"category\": \"reporters:federal\",\n",
      "            \"reporter\": \"Am. Dec.\",\n",
      "            \"opinion_index\": 0\n",
      "        },\n",
      "        {\n",
      "            \"cite\": \"11 Mass. 67\",\n",
      "            \"category\": \"reporters:state\",\n",
      "            \"reporter\": \"Mass.\",\n",
      "            \"case_ids\": [\n",
      "                2053436\n",
      "            ],\n",
      "            \"opinion_index\": 0,\n",
      "            \"case_paths\": [\n",
      "                \"/mass/11/0068-01\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"cite\": \"11 Mass. 63\",\n",
      "            \"category\": \"reporters:state\",\n",
      "            \"reporter\": \"Mass.\",\n",
      "            \"case_ids\": [\n",
      "                2053438\n",
      "            ],\n",
      "            \"opinion_index\": 0,\n",
      "            \"case_paths\": [\n",
      "                \"/mass/11/0065-01\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"cite\": \"21 Stat. 338\",\n",
      "            \"category\": \"laws:leg_session\",\n",
      "            \"reporter\": \"Stat.\",\n",
      "            \"opinion_index\": 0\n",
      "        },\n",
      "        {\n",
      "            \"cite\": \"21 Stat. 3\",\n",
      "            \"category\": \"laws:leg_session\",\n",
      "            \"reporter\": \"Stat.\",\n",
      "            \"opinion_index\": 0\n",
      "        }\n",
      "    ],\n",
      "    \"analysis\": {\n",
      "        \"cardinality\": 416,\n",
      "        \"char_count\": 6764,\n",
      "        \"ocr_confidence\": 0.645,\n",
      "        \"pagerank\": {\n",
      "            \"raw\": 4.03580807328026e-08,\n",
      "            \"percentile\": 0.20520520694449754\n",
      "        },\n",
      "        \"sha256\": \"50f1631f5020f754f3291ca4467f80204cd2fe61308e2afe1caf02925b493229\",\n",
      "        \"simhash\": \"1:d8b7a583688f714b\",\n",
      "        \"word_count\": 1210\n",
      "    },\n",
      "    \"last_updated\": \"2024-02-27T16:57:40.052731+00:00\",\n",
      "    \"provenance\": {\n",
      "        \"date_added\": \"2019-08-29\",\n",
      "        \"source\": \"Harvard\",\n",
      "        \"batch\": \"2018\"\n",
      "    },\n",
      "    \"casebody\": {\n",
      "        \"judges\": [],\n",
      "        \"parties\": [\n",
      "            \"In re JESSE SCOTT OLIVER, Minor.\"\n",
      "        ],\n",
      "        \"opinions\": [\n",
      "            {\n",
      "                \"text\": \"DAWSON, District Judge.\\nPetitioner, by his guardian, ad litem, sets forth that he is unlawfully restrained of his liberty by Lieutenant Commander J. S. Newell, naval officer in charge at this station, and in command of the United States steamer and man-of-war Pinta. He states that he was enlisted into the United States navy before he had attained his majority, and claims that the contract of enlistment is voidable, and that he is entitled to his discharge.\\nThe contract of enlistment in this case, which is similar to all contracts of enlistment in the United States navy, sets forth that petitioner was enlisted on the 8th day of July, 1886, at Mare Island, Cal., to serve as a common seaman for 3 years; that he was at the time of his enlistment 18 years and 7 months old, and that the consent of his parents or guardian had not been obtained. A writ of habeas corpus was issued, made returnable on October 29, 1887, at which time the defendant made return to the suit, embodying substantially the contract of enlistment, and producing the body of Scott Oliver in court. The only evidence in the case is \\u25a0the written contract of enlistment, signed by the petitioner, in which he \\\"states his age to be 18 years and 7 months. The question presented is, can a minor over\\\" 18 years of age bind himself by a contract of enlistment in the United States navy, without the consent of his parents or guardian ?\\nSection 1418, Rev. St. [U. S. Comp. St. 1901, p. 1007], provides that \\u201cboys between the ages of sixteen and eighteen years may be enlisted to serve in the navy until they shall arrive at the age of twent3'-one years; other persons may be enlisted to serve for a period not exceeding five years, unless sooner discharged by direction of the President.\\u201d\\nAgain, section 1419 [U. S. Comp. St. 1901, p. 1007], provides that \\u201cminors between the age of sixteen and eighteen j^ears shall not be enlisted for the naval service without the consent of their parents or guardian.\\u201d The sections quoted were enacted by Congress in. March, 1837, and have been carried forward in the various revisions of the statute since that time.\\nBy an act of Congress approved May 12, 1879 (21 Stat. 3, c. 5), it is provided that no minor under the age of 15 years shall be enlisted in the naval service. Supplement to Rev. St. vol. 1, p. 484 [Q. S. Comp. St. 1901, pp. 1007, 1008]. During the session of Congress of 1881 the former sections in relation to enlistments of minors were again amended as follows:\\n\\u201cThat sections fourteen hundred and eighteen, fourteen hundred and nineteen, fourteen hundred and twenty, as heretofore amended, relating to enlistment of minors in the naval service, be and hereby are amended by striking out the word \\u2018fifteen\\u2019 and inserting in its stead the word \\u2018fourteen.\\u2019 \\u201d\\nThis act was approved on the 23d day of February, 1881 (21 Stat. 338, c. 73). See Rev. St. Supp. p. 595 [U. S. Comp. St. 190j, pp. 1007, 1008]. From these amendments it is quite clear the Congress intended no change as to the right of a minor over the age of 18 years to bind himself by a contract of enlistment. It will be observed that there is- a difference in the matter of legal enlistments in the army and in the navy in regard to age. Section 1117, Rev. St. [U. S. Comp. St. 1901, p. 813], in relation to enlistments in the army, forbids the enlistment of any person under the age of 21 years, without the consent of his parents or guardian.\\nCounsel seems to confound the two provisions, or rather to lose sight of the clear distinction, in the law. The rules of the common law that infants may repudiate their con.tracts after attaining their majority, except where beneficial \\u2014as when made for supplying the necessities of life and the like \\u2014 can have no application to a contract of this nature. It is unlike a contract between private parties. It is an agreement to serve the government, for a period determined by the law, until the minor shall have attained his majority. The government is entitled, by virtue of its sovereignty, to require the services of any or all of its able-bodied citizens, of whatever age, in cases of public exigency. This right, being exercised for the common good, must be regarded as paramount to all individual claims.\\nIt is a part of the law of public policy that neither the rights at common law of the minor contractor nor those of his parent, guardian, or master shall be asserted against the United States, except when expressly recognized by existing statute. The right of the parent, or other person irr loco parentis, to object to the enlistment of a minor in the navy, is clearly limited to cases where the minor is but 18 years of age. Jf he is above that age, and under 21 years of age, he can bind himself by enlisting until he attains his majority, at which time his term expires by operation of law, and at which time the law recognizes his right to choose his vocation and pursue it. This is manifestly the meaning of the law, else adult persons enlisting would not be required to enlist to serve for a period of five years. It has been held on very high authority that enlistments in the navy, though, made without consent of the parent or guardian, are binding, and the minor cannot avoid them. See U. S. v. Bainbridge, 1 Mason, 71, Fed. Cas. No. 14,497; U. S. v. Blakeney, 3 Grat. 405.\\nBut it is otherwise as to enlistments in the army. The distinction is clearly made in the statute, and has been sustained by the courts. See U. S. v. Bainbridge, 1 Mason, 71, Fed. Cas. No. 14,497; Commonwealth v. Harrison, 11 Mass. 63; Com. v. Cushing, 11 Mass. 67, 6 Am. Dec. 156.\\nIn this case it is not disputed that the petitioner signed his name to the contract of enlistment, and represented his age to be 18 years and 7 months. In certain cases, and under certain circumstances, the law of estoppel will apply to minors. That a minor is responsible in damages for his torts and frauds is well settled in the law. If he falsely represents-his age for the purpose of inducing another person to contract with him, he is estopped from afterwards denying it.. See Bigelow on Estoppel, pp. 486, 487.\\nIt follows that the prayer of the petitioner must be denied, and that he be remanded to the custody of Lieutenant Commander Newell and his successors until he is 21 years of age, unless discharged for some other cause; and it is so ordered-\",\n",
      "                \"type\": \"majority\",\n",
      "                \"author\": \"DAWSON, District Judge.\"\n",
      "            }\n",
      "        ],\n",
      "        \"attorneys\": [\n",
      "            \"W. Clark, for petitioner.\",\n",
      "            \"A. McCracken, contra.\"\n",
      "        ],\n",
      "        \"corrections\": \"\",\n",
      "        \"head_matter\": \"In re JESSE SCOTT OLIVER, Minor.\\n(Sitka.\\nOctober 31, 1887.)\\nNo. 95.\\n1. Army and Navy \\u2014 Enlistment\\u2014Habeas Corpus \\u2014 Infants.\\nA minor over eighteen and under twenty-one years of age may enter into a binding contract of enlistment in the navy,' and will not for that reason alone be discharged on habeas corpus.\\nPetition for Habeas Corpus.\\nDenied.\\nW. Clark, for petitioner.\\nA. McCracken, contra.\"\n",
      "    },\n",
      "    \"file_name\": \"0001-01\",\n",
      "    \"first_page_order\": 25,\n",
      "    \"last_page_order\": 28\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def load_and_inspect_json(folder_path):\n",
    "    \"\"\"Inspect the structure of the first JSON file to debug the issue.\"\"\"\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.json'):\n",
    "            with open(os.path.join(folder_path, file_name), 'r') as f:\n",
    "                data = json.load(f)\n",
    "                print(f\"File: {file_name}\")\n",
    "                print(json.dumps(data, indent=4))  # Pretty print the JSON structure\n",
    "                break  # Stop after inspecting the first file\n",
    "\n",
    "# Set the folder path to your JSON directory\n",
    "folder_path = \"json/\"\n",
    "load_and_inspect_json(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a530884-b15f-4025-adad-d0070ce391a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated metadata saved to data/metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Data Loading\n",
    "def load_json_files(folder_path):\n",
    "    \"\"\"Load all JSON files from a given folder into a list of dictionaries.\"\"\"\n",
    "    all_data = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.json'):\n",
    "            with open(os.path.join(folder_path, file_name), 'r') as f:\n",
    "                data = json.load(f)\n",
    "                all_data.append(data)\n",
    "    return all_data\n",
    "\n",
    "# Preprocessing Functions\n",
    "def preprocess_case_text(text):\n",
    "    \"\"\"Clean and standardize case text.\"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "    text = re.sub(r'[^\\w\\s.,;:]', '', text)  # Remove special characters\n",
    "    return text.strip()\n",
    "\n",
    "def preprocess_data_with_casebody(data):\n",
    "    \"\"\"Preprocess data by cleaning text and extracting detailed case text.\"\"\"\n",
    "    preprocessed_data = []\n",
    "    for case in data:\n",
    "        # Extract detailed text from 'casebody > opinions > text'\n",
    "        casebody_opinions = case.get(\"casebody\", {}).get(\"opinions\", [])\n",
    "        detailed_text = \" \".join(opinion.get(\"text\", \"\") for opinion in casebody_opinions)\n",
    "\n",
    "        processed_case = {\n",
    "            \"id\": case.get(\"id\"),\n",
    "            \"name\": case.get(\"name\", \"\").strip(),\n",
    "            \"abbreviation\": case.get(\"name_abbreviation\", \"\").strip(),\n",
    "            \"decision_date\": case.get(\"decision_date\", \"\").strip(),\n",
    "            \"jurisdiction\": case.get(\"jurisdiction\", {}).get(\"name\", \"\").strip(),\n",
    "            \"cleaned_text\": preprocess_case_text(detailed_text) if detailed_text else \"No text available\",\n",
    "        }\n",
    "        preprocessed_data.append(processed_case)\n",
    "    return preprocessed_data\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"json/\"  # Path to your folder containing JSON files\n",
    "    data = load_json_files(folder_path)  # Load JSON files\n",
    "    preprocessed_data = preprocess_data_with_casebody(data)  # Preprocess data\n",
    "    \n",
    "    # Save to metadata file for further processing\n",
    "    output_metadata_file = \"data/metadata.json\"\n",
    "    with open(output_metadata_file, \"w\") as f:\n",
    "        json.dump(preprocessed_data, f)\n",
    "\n",
    "    print(f\"Updated metadata saved to {output_metadata_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fdd6abc-8916-48e1-a5da-6528769c754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColBERT Class\n",
    "class ColBERT:\n",
    "    def __init__(self, pretrained_model_name='bert-base-uncased'):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_model_name)\n",
    "        self.model = BertModel.from_pretrained(pretrained_model_name)\n",
    "        self.model.eval()\n",
    "\n",
    "    def generate_embeddings(self, text):\n",
    "        \"\"\"Generate dense embeddings for a given text.\"\"\"\n",
    "        tokens = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**tokens)\n",
    "            token_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "            mask = tokens['attention_mask'].squeeze(0).bool()\n",
    "            return token_embeddings[mask].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84fdbbaf-0f49-420b-8d7e-d9d12963dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Preprocessing\n",
    "def preprocess_query(query):\n",
    "    \"\"\"Normalize and clean the query for better matching.\"\"\"\n",
    "    query = re.sub(r'\\s+', ' ', query)  # Remove extra whitespace\n",
    "    query = re.sub(r'[^\\w\\s.,;:]', '', query)  # Remove special characters\n",
    "    query = query.strip().lower()\n",
    "\n",
    "    # List of common filler words or phrases to remove\n",
    "    filler_words = [\n",
    "        'what about', 'can you', 'could you', 'please', 'tell me', \n",
    "        'show me', 'find', 'search for', 'give me', 'how about', \n",
    "        'do you know', 'any info on', 'what is', 'can you tell me about', \n",
    "        'let me know', 'is there', 'is it', 'is this', 'i want to know', \n",
    "        'i am looking for', 'can you find', 'what is the status of', \n",
    "        'what do you know', 'have you heard of'\n",
    "    ]\n",
    "    \n",
    "    # Remove common filler words or phrases\n",
    "    for filler in filler_words:\n",
    "        query = re.sub(r'\\b' + re.escape(filler) + r'\\b', '', query)\n",
    "\n",
    "    # Normalize \"v.\" to \"v\" and \"vs\" to \"v\" for consistency\n",
    "    query = query.replace('v.', 'v').replace('vs', 'v')\n",
    "\n",
    "    # Clean up any remaining extra whitespace after removing filler words\n",
    "    query = re.sub(r'\\s+', ' ', query).strip()\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef36d37d-0e34-4d4f-8202-9556053b742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def is_similar(a, b, threshold=0.8):\n",
    "    \"\"\"Check if two strings are similar using SequenceMatcher.\"\"\"\n",
    "    return SequenceMatcher(None, a, b).ratio() > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30e3ea5d-76b7-492f-8f94-a594153b0e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colbert_retrieve(query, embeddings_file, metadata_file, top_k=5):\n",
    "    \"\"\"Retrieve relevant legal cases based on a query.\"\"\"\n",
    "    embeddings = np.load(embeddings_file, allow_pickle=True)\n",
    "    with open(metadata_file, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    colbert = ColBERT()\n",
    "    query_normalized = preprocess_query(query)  # Normalize the query\n",
    "    print(f\"Normalized Query: '{query_normalized}'\")  # Debugging query normalization\n",
    "\n",
    "    query_tokens = colbert.tokenizer(query_normalized, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # Generate query embeddings\n",
    "    with torch.no_grad():\n",
    "        query_outputs = colbert.model(**query_tokens)\n",
    "        query_embeddings = query_outputs.last_hidden_state.squeeze(0)\n",
    "        mask = query_tokens['attention_mask'].squeeze(0).bool()\n",
    "        query_embeddings = query_embeddings[mask].numpy()\n",
    "\n",
    "    scores = []\n",
    "    filtered_results = []\n",
    "\n",
    "    exact_match_weight = 50  # Boost for exact matches\n",
    "\n",
    "    for i, doc in enumerate(metadata):\n",
    "        exact_match_score = 0\n",
    "\n",
    "        # Normalize metadata fields\n",
    "        case_name = doc[\"name\"].lower().replace('v.', 'v').replace('vs', 'v') if doc.get(\"name\") else \"\"\n",
    "        abbreviation = doc[\"abbreviation\"].lower().replace('v.', 'v').replace('vs', 'v') if doc.get(\"abbreviation\") else \"\"\n",
    "        print(f\"Normalized Metadata: '{case_name}' (Case Name), '{abbreviation}' (Abbreviation)\")  # Debugging\n",
    "\n",
    "        # Exact match and similarity checks\n",
    "        if query_normalized == case_name or query_normalized == abbreviation:\n",
    "            exact_match_score = exact_match_weight\n",
    "            print(f\"Exact Match Found: Query='{query_normalized}' matches Case Name='{case_name}' or Abbreviation='{abbreviation}'\")\n",
    "            filtered_results.append(doc)\n",
    "        elif is_similar(query_normalized, case_name) or is_similar(query_normalized, abbreviation):\n",
    "            exact_match_score = exact_match_weight // 2  # Partial match has lower weight\n",
    "            print(f\"Partial Match Found: '{query_normalized}' matches '{case_name}' or '{abbreviation}'\")\n",
    "            filtered_results.append(doc)\n",
    "\n",
    "        # Compute document embeddings similarity\n",
    "        doc_embeddings = embeddings[i]\n",
    "        similarity_matrix = cosine_similarity(query_embeddings, doc_embeddings)\n",
    "        max_similarities = similarity_matrix.max(axis=1)\n",
    "        embedding_score = max_similarities.sum()\n",
    "\n",
    "        # Final score combines exact match and embedding similarity\n",
    "        final_score = exact_match_score + embedding_score\n",
    "        scores.append((final_score, i))\n",
    "\n",
    "    # Sort the scores in descending order\n",
    "    scores = sorted(scores, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Generate results based on the sorted scores\n",
    "    results = [\n",
    "        {\n",
    "            \"id\": metadata[i][\"id\"],\n",
    "            \"name\": metadata[i][\"name\"],\n",
    "            \"abbreviation\": metadata[i][\"abbreviation\"],\n",
    "            \"decision_date\": metadata[i][\"decision_date\"],\n",
    "            \"jurisdiction\": metadata[i][\"jurisdiction\"],\n",
    "            \"cleaned_text\": metadata[i].get(\"cleaned_text\", \"No text available\"),\n",
    "            \"file_name\": metadata[i].get(\"file_name\", \"Unknown\"),  # Add file name for manual lookup\n",
    "            \"score\": final_score,\n",
    "        }\n",
    "        for final_score, i in scores[:top_k]\n",
    "    ]\n",
    "\n",
    "    return results, filtered_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a15604e-e557-4d3d-9cdb-ab3b4bebb4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colbert_retrieve(query, embeddings_file, metadata_file, top_k=5):\n",
    "    embeddings = np.load(embeddings_file, allow_pickle=True)\n",
    "    with open(metadata_file, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    colbert = ColBERT()\n",
    "    query = preprocess_query(query)  # Normalize the query\n",
    "    query_tokens = colbert.tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        query_outputs = colbert.model(**query_tokens)\n",
    "        query_embeddings = query_outputs.last_hidden_state.squeeze(0)\n",
    "        mask = query_tokens['attention_mask'].squeeze(0).bool()\n",
    "        query_embeddings = query_embeddings[mask].numpy()\n",
    "\n",
    "    scores = []\n",
    "    filtered_results = []\n",
    "\n",
    "    exact_match_weight = 50\n",
    "    for i, doc in enumerate(metadata):\n",
    "        exact_match_score = 0\n",
    "        case_name = doc[\"name\"].lower() if doc.get(\"name\") else \"\"\n",
    "        abbreviation = doc[\"abbreviation\"].lower() if doc.get(\"abbreviation\") else \"\"\n",
    "\n",
    "        case_name = case_name.replace('v.', 'v').replace('vs', 'v')\n",
    "        abbreviation = abbreviation.replace('v.', 'v').replace('vs', 'v')\n",
    "\n",
    "        if query == case_name or query == abbreviation:\n",
    "            exact_match_score = exact_match_weight\n",
    "            filtered_results.append(doc)\n",
    "\n",
    "        doc_embeddings = embeddings[i]\n",
    "        similarity_matrix = cosine_similarity(query_embeddings, doc_embeddings)\n",
    "        max_similarities = similarity_matrix.max(axis=1)\n",
    "        embedding_score = max_similarities.sum()\n",
    "        final_score = exact_match_score + embedding_score\n",
    "        scores.append((final_score, i))\n",
    "\n",
    "    scores = sorted(scores, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    results = [\n",
    "        {\n",
    "            \"id\": metadata[i][\"id\"],\n",
    "            \"name\": metadata[i][\"name\"],\n",
    "            \"abbreviation\": metadata[i][\"abbreviation\"],\n",
    "            \"decision_date\": metadata[i][\"decision_date\"],\n",
    "            \"jurisdiction\": metadata[i][\"jurisdiction\"],\n",
    "            \"cleaned_text\": metadata[i].get(\"cleaned_text\", \"No text available\"),\n",
    "            \"file_name\": metadata[i].get(\"file_name\", \"Unknown\"),  # Add file name for manual lookup\n",
    "            \"score\": final_score,\n",
    "        }\n",
    "        for final_score, i in scores[:top_k]\n",
    "    ]\n",
    "\n",
    "    return results, filtered_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c72b269f-ec06-4e93-b13b-5ea253ddf2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(query, retrieved_docs):\n",
    "    \"\"\"Generate a summary using RAG for the most relevant content.\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "    # Combine cleaned_text of retrieved documents\n",
    "    context = \" \".join([doc.get('cleaned_text', '') for doc in retrieved_docs if doc.get('cleaned_text')])\n",
    "\n",
    "    if not context.strip():\n",
    "        return \"No relevant document content found for summarization.\"\n",
    "\n",
    "    # Prepare input for the summarization model\n",
    "    input_text = f\"Query: {query} Context: {context}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs.input_ids, max_length=200, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8fc5c24-bc60-49ac-b7d2-9b6c9dddf355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_system():\n",
    "    print(\"Welcome to the Legal Case Retrieval System!\")\n",
    "    print(\"Type 'exit' at any point to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        print(\"\\nSelect a query type:\")\n",
    "        print(\"1. Search by Name\")\n",
    "        print(\"2. Search by Abbreviation\")\n",
    "        print(\"3. Search by Decision Date\")\n",
    "        print(\"4. Search by Jurisdiction\")\n",
    "        print(\"5. Custom Legal Query\")\n",
    "        print(\"Type 'exit' to quit.\")\n",
    "        choice = input(\"\\nEnter choice (1-5): \").strip()\n",
    "\n",
    "        if choice.lower() == \"exit\":\n",
    "            print(\"Exiting the system. Goodbye!\")\n",
    "            break  # Properly exit the loop\n",
    "\n",
    "        query = \"\"\n",
    "        if choice == \"1\":\n",
    "            query = input(\"Enter case name: \").strip()\n",
    "        elif choice == \"2\":\n",
    "            query = input(\"Enter case abbreviation: \").strip()\n",
    "        elif choice == \"3\":\n",
    "            query = input(\"Enter decision date (YYYY-MM-DD): \").strip()\n",
    "        elif choice == \"4\":\n",
    "            query = input(\"Enter jurisdiction: \").strip()\n",
    "        elif choice == \"5\":\n",
    "            query = input(\"Enter your custom legal query: \").strip()\n",
    "        else:\n",
    "            print(\"Invalid choice. Please try again.\")\n",
    "            continue  # Restart the loop for invalid input\n",
    "\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Exiting the system. Goodbye!\")\n",
    "            break  # Properly exit the loop\n",
    "\n",
    "        try:\n",
    "            # Retrieve results using ColBERT retrieval function\n",
    "            results, filtered_results = colbert_retrieve(query, \"data/embeddings.npy\", \"data/metadata.json\")\n",
    "\n",
    "            # Display results\n",
    "            print(\"\\nRetrieved Cleaned Texts (or Detailed Texts):\")\n",
    "            for res in results:\n",
    "                print(f\"File: {res['file_name']} | Document ID: {res['id']}, Name: {res['name']}, \"\n",
    "                      f\"Cleaned Text Snippet: {res['cleaned_text'][:100]}...\")\n",
    "\n",
    "            print(\"\\nTop results:\")\n",
    "            for res in results:\n",
    "                print(f\"ID: {res['id']}, Name: {res['name']}, Score: {res['score']:.4f}\")\n",
    "\n",
    "            # Advanced summary generation\n",
    "            if results:\n",
    "                print(\"\\nGenerating advanced summary...\\n\")\n",
    "                advanced_summary = generate_summary(query, results)\n",
    "                print(\"Generated Summary:\")\n",
    "                print(advanced_summary)\n",
    "            else:\n",
    "                print(\"No relevant documents found. Try refining your query.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n",
    "            continue  # Restart the loop on error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a762f3-2bd5-4daa-a352-76715ed3a644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Legal Case Retrieval System!\n",
      "Type 'exit' at any point to quit.\n",
      "\n",
      "\n",
      "Select a query type:\n",
      "1. Search by Name\n",
      "2. Search by Abbreviation\n",
      "3. Search by Decision Date\n",
      "4. Search by Jurisdiction\n",
      "5. Custom Legal Query\n",
      "Type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter choice (1-5):  1\n",
      "Enter case name:  Valentine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved Cleaned Texts (or Detailed Texts):\n",
      "File: Unknown | Document ID: 8503986, Name: In re JESSE SCOTT OLIVER, Minor, Cleaned Text Snippet: DAWSON, District Judge. Petitioner, by his guardian, ad litem, sets forth that he is unlawfully rest...\n",
      "File: Unknown | Document ID: 8504008, Name: UNITED STATES v. THE NORTH-WEST TRADING CO. et al., Cleaned Text Snippet: DAWSON, District Judge. On June 6, 1888, the United States District Attorney for the District of Ala...\n",
      "File: Unknown | Document ID: 8504024, Name: MYERS v. SWINEFORD, Cleaned Text Snippet: DAAVSON, District Judge. This was an action of assumpsit, brought by plaintiff against the defendant...\n",
      "File: Unknown | Document ID: 8504052, Name: Ex parte DUBUQUE, Cleaned Text Snippet: KEATEEY, District Judge. It appears that on the 2ist day of August, 1888, Eouis E. Williams, a Unite...\n",
      "File: Unknown | Document ID: 8504080, Name: GARSIDE v. NORVAL, Cleaned Text Snippet: KFATUFY, District Judge. On the 3d of October, 1888, the plaintiff filed a complaint in the office o...\n",
      "\n",
      "Top results:\n",
      "ID: 8503986, Name: In re JESSE SCOTT OLIVER, Minor, Score: 1.6010\n",
      "ID: 8504008, Name: UNITED STATES v. THE NORTH-WEST TRADING CO. et al., Score: 1.6010\n",
      "ID: 8504024, Name: MYERS v. SWINEFORD, Score: 1.6010\n",
      "ID: 8504052, Name: Ex parte DUBUQUE, Score: 1.6010\n",
      "ID: 8504080, Name: GARSIDE v. NORVAL, Score: 1.6010\n",
      "\n",
      "Generating advanced summary...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        query_system()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nSystem interrupted. Exiting gracefully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d7c487-9264-4f04-9759-4a85b1ad0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Normalized Query: '{query_normalized}'\")\n",
    "print(f\"Normalized Metadata: '{case_name}' (Case Name), '{abbreviation}' (Abbreviation)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c7febd-ea28-461e-8eb4-48bc10a38216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
