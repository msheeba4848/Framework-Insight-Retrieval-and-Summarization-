{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c26c951b-c06c-48c4-b1c9-e9f385558f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install \n",
    "#!pip install torch transformers llama-index scikit-learn numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec160237-8bc0-4a3d-ab5d-9b946dd4b9ad",
   "metadata": {},
   "source": [
    "## Load Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9dfe5abd-6206-4990-a075-2defe23a1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fd20e245-40d1-45f5-b739-4a579a781626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved at: data/output_cases.csv\n"
     ]
    }
   ],
   "source": [
    "# json to csv for data exploration\n",
    "\n",
    "def json_to_csv(json_dir, output_csv):\n",
    "    \"\"\"\n",
    "    Converts all JSON files in a directory into a single CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        json_dir (str): Path to the directory containing JSON files.\n",
    "        output_csv (str): Path to save the output CSV file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    # Iterate over all JSON files in the directory\n",
    "    for file_name in os.listdir(json_dir):\n",
    "        if file_name.endswith(\".json\"):\n",
    "            file_path = os.path.join(json_dir, file_name)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                # Load the JSON data\n",
    "                data = json.load(file)\n",
    "                \n",
    "                # Flatten the JSON structure and extract relevant data\n",
    "                row = {\n",
    "                    \"id\": data.get(\"id\"),\n",
    "                    \"name\": data.get(\"name\"),\n",
    "                    \"abbreviation\": data.get(\"name_abbreviation\"),\n",
    "                    \"decision_date\": data.get(\"decision_date\"),\n",
    "                    \"court_name\": data.get(\"court\", {}).get(\"name\"),\n",
    "                    \"jurisdiction_name\": data.get(\"jurisdiction\", {}).get(\"name\"),\n",
    "                    \"word_count\": data.get(\"analysis\", {}).get(\"word_count\"),\n",
    "                    \"char_count\": data.get(\"analysis\", {}).get(\"char_count\"),\n",
    "                    \"ocr_confidence\": data.get(\"analysis\", {}).get(\"ocr_confidence\"),\n",
    "                    \"case_text\": \" \".join([opinion[\"text\"] for opinion in data.get(\"casebody\", {}).get(\"opinions\", [])]),\n",
    "                }\n",
    "                all_data.append(row)\n",
    "    \n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"CSV file saved at: {output_csv}\")\n",
    "\n",
    "# Specify the path to the JSON directory and output CSV file\n",
    "json_dir = \"json/\"\n",
    "output_csv = \"data/output_cases.csv\"\n",
    "\n",
    "# Convert JSON files to CSV\n",
    "json_to_csv(json_dir, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a7fda4fb-63a1-430a-b422-3bf5e150fce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: 0001-01.json\n",
      "{\n",
      "    \"id\": 8503986,\n",
      "    \"name\": \"In re JESSE SCOTT OLIVER, Minor\",\n",
      "    \"name_abbreviation\": \"In re Oliver\",\n",
      "    \"decision_date\": \"1887-10-31\",\n",
      "    \"docket_number\": \"No. 95\",\n",
      "    \"first_page\": \"1\",\n",
      "    \"last_page\": \"4\",\n",
      "    \"citations\": [\n",
      "        {\n",
      "            \"type\": \"official\",\n",
      "            \"cite\": \"1 Alaska 1\"\n",
      "        }\n",
      "    ],\n",
      "    \"court\": {\n",
      "        \"name_abbreviation\": \"Alaska Dist. Ct.\",\n",
      "        \"id\": 23837,\n",
      "        \"name\": \"Alaska District Court\"\n",
      "    },\n",
      "    \"jurisdiction\": {\n",
      "        \"id\": 53,\n",
      "        \"name_long\": \"Alaska\",\n",
      "        \"name\": \"Alaska\"\n",
      "    },\n",
      "    \"cites_to\": [\n",
      "        {\n",
      "            \"cite\": \"6 Am. Dec. 156\",\n",
      "            \"category\": \"reporters:federal\",\n",
      "            \"reporter\": \"Am. Dec.\",\n",
      "            \"opinion_index\": 0\n",
      "        },\n",
      "        {\n",
      "            \"cite\": \"11 Mass. 67\",\n",
      "            \"category\": \"reporters:state\",\n",
      "            \"reporter\": \"Mass.\",\n",
      "            \"case_ids\": [\n",
      "                2053436\n",
      "            ],\n",
      "            \"opinion_index\": 0,\n",
      "            \"case_paths\": [\n",
      "                \"/mass/11/0068-01\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"cite\": \"11 Mass. 63\",\n",
      "            \"category\": \"reporters:state\",\n",
      "            \"reporter\": \"Mass.\",\n",
      "            \"case_ids\": [\n",
      "                2053438\n",
      "            ],\n",
      "            \"opinion_index\": 0,\n",
      "            \"case_paths\": [\n",
      "                \"/mass/11/0065-01\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"cite\": \"21 Stat. 338\",\n",
      "            \"category\": \"laws:leg_session\",\n",
      "            \"reporter\": \"Stat.\",\n",
      "            \"opinion_index\": 0\n",
      "        },\n",
      "        {\n",
      "            \"cite\": \"21 Stat. 3\",\n",
      "            \"category\": \"laws:leg_session\",\n",
      "            \"reporter\": \"Stat.\",\n",
      "            \"opinion_index\": 0\n",
      "        }\n",
      "    ],\n",
      "    \"analysis\": {\n",
      "        \"cardinality\": 416,\n",
      "        \"char_count\": 6764,\n",
      "        \"ocr_confidence\": 0.645,\n",
      "        \"pagerank\": {\n",
      "            \"raw\": 4.03580807328026e-08,\n",
      "            \"percentile\": 0.20520520694449754\n",
      "        },\n",
      "        \"sha256\": \"50f1631f5020f754f3291ca4467f80204cd2fe61308e2afe1caf02925b493229\",\n",
      "        \"simhash\": \"1:d8b7a583688f714b\",\n",
      "        \"word_count\": 1210\n",
      "    },\n",
      "    \"last_updated\": \"2024-02-27T16:57:40.052731+00:00\",\n",
      "    \"provenance\": {\n",
      "        \"date_added\": \"2019-08-29\",\n",
      "        \"source\": \"Harvard\",\n",
      "        \"batch\": \"2018\"\n",
      "    },\n",
      "    \"casebody\": {\n",
      "        \"judges\": [],\n",
      "        \"parties\": [\n",
      "            \"In re JESSE SCOTT OLIVER, Minor.\"\n",
      "        ],\n",
      "        \"opinions\": [\n",
      "            {\n",
      "                \"text\": \"DAWSON, District Judge.\\nPetitioner, by his guardian, ad litem, sets forth that he is unlawfully restrained of his liberty by Lieutenant Commander J. S. Newell, naval officer in charge at this station, and in command of the United States steamer and man-of-war Pinta. He states that he was enlisted into the United States navy before he had attained his majority, and claims that the contract of enlistment is voidable, and that he is entitled to his discharge.\\nThe contract of enlistment in this case, which is similar to all contracts of enlistment in the United States navy, sets forth that petitioner was enlisted on the 8th day of July, 1886, at Mare Island, Cal., to serve as a common seaman for 3 years; that he was at the time of his enlistment 18 years and 7 months old, and that the consent of his parents or guardian had not been obtained. A writ of habeas corpus was issued, made returnable on October 29, 1887, at which time the defendant made return to the suit, embodying substantially the contract of enlistment, and producing the body of Scott Oliver in court. The only evidence in the case is \\u25a0the written contract of enlistment, signed by the petitioner, in which he \\\"states his age to be 18 years and 7 months. The question presented is, can a minor over\\\" 18 years of age bind himself by a contract of enlistment in the United States navy, without the consent of his parents or guardian ?\\nSection 1418, Rev. St. [U. S. Comp. St. 1901, p. 1007], provides that \\u201cboys between the ages of sixteen and eighteen years may be enlisted to serve in the navy until they shall arrive at the age of twent3'-one years; other persons may be enlisted to serve for a period not exceeding five years, unless sooner discharged by direction of the President.\\u201d\\nAgain, section 1419 [U. S. Comp. St. 1901, p. 1007], provides that \\u201cminors between the age of sixteen and eighteen j^ears shall not be enlisted for the naval service without the consent of their parents or guardian.\\u201d The sections quoted were enacted by Congress in. March, 1837, and have been carried forward in the various revisions of the statute since that time.\\nBy an act of Congress approved May 12, 1879 (21 Stat. 3, c. 5), it is provided that no minor under the age of 15 years shall be enlisted in the naval service. Supplement to Rev. St. vol. 1, p. 484 [Q. S. Comp. St. 1901, pp. 1007, 1008]. During the session of Congress of 1881 the former sections in relation to enlistments of minors were again amended as follows:\\n\\u201cThat sections fourteen hundred and eighteen, fourteen hundred and nineteen, fourteen hundred and twenty, as heretofore amended, relating to enlistment of minors in the naval service, be and hereby are amended by striking out the word \\u2018fifteen\\u2019 and inserting in its stead the word \\u2018fourteen.\\u2019 \\u201d\\nThis act was approved on the 23d day of February, 1881 (21 Stat. 338, c. 73). See Rev. St. Supp. p. 595 [U. S. Comp. St. 190j, pp. 1007, 1008]. From these amendments it is quite clear the Congress intended no change as to the right of a minor over the age of 18 years to bind himself by a contract of enlistment. It will be observed that there is- a difference in the matter of legal enlistments in the army and in the navy in regard to age. Section 1117, Rev. St. [U. S. Comp. St. 1901, p. 813], in relation to enlistments in the army, forbids the enlistment of any person under the age of 21 years, without the consent of his parents or guardian.\\nCounsel seems to confound the two provisions, or rather to lose sight of the clear distinction, in the law. The rules of the common law that infants may repudiate their con.tracts after attaining their majority, except where beneficial \\u2014as when made for supplying the necessities of life and the like \\u2014 can have no application to a contract of this nature. It is unlike a contract between private parties. It is an agreement to serve the government, for a period determined by the law, until the minor shall have attained his majority. The government is entitled, by virtue of its sovereignty, to require the services of any or all of its able-bodied citizens, of whatever age, in cases of public exigency. This right, being exercised for the common good, must be regarded as paramount to all individual claims.\\nIt is a part of the law of public policy that neither the rights at common law of the minor contractor nor those of his parent, guardian, or master shall be asserted against the United States, except when expressly recognized by existing statute. The right of the parent, or other person irr loco parentis, to object to the enlistment of a minor in the navy, is clearly limited to cases where the minor is but 18 years of age. Jf he is above that age, and under 21 years of age, he can bind himself by enlisting until he attains his majority, at which time his term expires by operation of law, and at which time the law recognizes his right to choose his vocation and pursue it. This is manifestly the meaning of the law, else adult persons enlisting would not be required to enlist to serve for a period of five years. It has been held on very high authority that enlistments in the navy, though, made without consent of the parent or guardian, are binding, and the minor cannot avoid them. See U. S. v. Bainbridge, 1 Mason, 71, Fed. Cas. No. 14,497; U. S. v. Blakeney, 3 Grat. 405.\\nBut it is otherwise as to enlistments in the army. The distinction is clearly made in the statute, and has been sustained by the courts. See U. S. v. Bainbridge, 1 Mason, 71, Fed. Cas. No. 14,497; Commonwealth v. Harrison, 11 Mass. 63; Com. v. Cushing, 11 Mass. 67, 6 Am. Dec. 156.\\nIn this case it is not disputed that the petitioner signed his name to the contract of enlistment, and represented his age to be 18 years and 7 months. In certain cases, and under certain circumstances, the law of estoppel will apply to minors. That a minor is responsible in damages for his torts and frauds is well settled in the law. If he falsely represents-his age for the purpose of inducing another person to contract with him, he is estopped from afterwards denying it.. See Bigelow on Estoppel, pp. 486, 487.\\nIt follows that the prayer of the petitioner must be denied, and that he be remanded to the custody of Lieutenant Commander Newell and his successors until he is 21 years of age, unless discharged for some other cause; and it is so ordered-\",\n",
      "                \"type\": \"majority\",\n",
      "                \"author\": \"DAWSON, District Judge.\"\n",
      "            }\n",
      "        ],\n",
      "        \"attorneys\": [\n",
      "            \"W. Clark, for petitioner.\",\n",
      "            \"A. McCracken, contra.\"\n",
      "        ],\n",
      "        \"corrections\": \"\",\n",
      "        \"head_matter\": \"In re JESSE SCOTT OLIVER, Minor.\\n(Sitka.\\nOctober 31, 1887.)\\nNo. 95.\\n1. Army and Navy \\u2014 Enlistment\\u2014Habeas Corpus \\u2014 Infants.\\nA minor over eighteen and under twenty-one years of age may enter into a binding contract of enlistment in the navy,' and will not for that reason alone be discharged on habeas corpus.\\nPetition for Habeas Corpus.\\nDenied.\\nW. Clark, for petitioner.\\nA. McCracken, contra.\"\n",
      "    },\n",
      "    \"file_name\": \"0001-01\",\n",
      "    \"first_page_order\": 25,\n",
      "    \"last_page_order\": 28\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def load_and_inspect_json(folder_path):\n",
    "    \"\"\"Inspect the structure of the first JSON file to debug the issue.\"\"\"\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.json'):\n",
    "            with open(os.path.join(folder_path, file_name), 'r') as f:\n",
    "                data = json.load(f)\n",
    "                print(f\"File: {file_name}\")\n",
    "                print(json.dumps(data, indent=4))  # Pretty print the JSON structure\n",
    "                break  # Stop after inspecting the first file\n",
    "\n",
    "# Set the folder path to your JSON directory\n",
    "folder_path = \"json/\"\n",
    "load_and_inspect_json(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9a530884-b15f-4025-adad-d0070ce391a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated metadata saved to data/metadata.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Data Loading\n",
    "def load_json_files(folder_path):\n",
    "    \"\"\"Load all JSON files from a given folder into a list of dictionaries.\"\"\"\n",
    "    all_data = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.json'):\n",
    "            with open(os.path.join(folder_path, file_name), 'r') as f:\n",
    "                data = json.load(f)\n",
    "                all_data.append(data)\n",
    "    return all_data\n",
    "\n",
    "# Date Standardization\n",
    "def standardize_date(date):\n",
    "    \"\"\"Standardize date to YYYY-MM-DD format.\"\"\"\n",
    "    try:\n",
    "        if len(date) == 4:  # Only year\n",
    "            return pd.to_datetime(date + '-01-01').strftime('%Y-%m-%d')\n",
    "        elif len(date) == 7:  # Year and month\n",
    "            return pd.to_datetime(date + '-01').strftime('%Y-%m-%d')\n",
    "        else:  # Full date\n",
    "            return pd.to_datetime(date).strftime('%Y-%m-%d')\n",
    "    except Exception:\n",
    "        return None  # Return None for invalid dates\n",
    "\n",
    "# Preprocessing Functions\n",
    "def preprocess_case_text(text):\n",
    "    \"\"\"Clean and standardize case text.\"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "    text = re.sub(r'[^\\w\\s.,;:]', '', text)  # Remove special characters\n",
    "    return text.strip()\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Lowercase and remove special characters for consistent normalization.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "    return text.strip()\n",
    "\n",
    "def preprocess_data_with_casebody(data):\n",
    "    \"\"\"Preprocess data by cleaning text and extracting detailed case text.\"\"\"\n",
    "    preprocessed_data = []\n",
    "    for case in data:\n",
    "        # Extract detailed text from 'casebody > opinions > text'\n",
    "        casebody_opinions = case.get(\"casebody\", {}).get(\"opinions\", [])\n",
    "        detailed_text = \" \".join(opinion.get(\"text\", \"\") for opinion in casebody_opinions)\n",
    "\n",
    "        # Standardize the decision_date\n",
    "        decision_date = standardize_date(case.get(\"decision_date\", \"\").strip())\n",
    "        normalized_date = decision_date.replace(\"-\", \"\") if decision_date else None\n",
    "\n",
    "        processed_case = {\n",
    "            \"id\": case.get(\"id\"),\n",
    "            \"name\": normalize_text(case.get(\"name\", \"\")),  # Normalize the case name\n",
    "            \"abbreviation\": normalize_text(case.get(\"name_abbreviation\", \"\")),  # Normalize abbreviation\n",
    "            \"decision_date\": decision_date,  # Standardized decision date\n",
    "            \"normalized_date\": normalized_date,  # Query-friendly normalized date\n",
    "            \"jurisdiction\": case.get(\"jurisdiction\", {}).get(\"name\", \"\").strip(),  # Keep jurisdiction unaltered\n",
    "            \"cleaned_text\": preprocess_case_text(detailed_text) if detailed_text else \"No text available\",\n",
    "        }\n",
    "        preprocessed_data.append(processed_case)\n",
    "    return preprocessed_data\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"json/\"  # Path to your folder containing JSON files\n",
    "    data = load_json_files(folder_path)  # Load JSON files\n",
    "    preprocessed_data = preprocess_data_with_casebody(data)  # Preprocess data\n",
    "    \n",
    "    # Save to metadata file for further processing\n",
    "    output_metadata_file = \"data/metadata.json\"\n",
    "    os.makedirs(os.path.dirname(output_metadata_file), exist_ok=True)  # Create output directory if not exists\n",
    "    with open(output_metadata_file, \"w\") as f:\n",
    "        json.dump(preprocessed_data, f, indent=4)\n",
    "\n",
    "    print(f\"Updated metadata saved to {output_metadata_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6fdd6abc-8916-48e1-a5da-6528769c754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColBERT Class\n",
    "class ColBERT:\n",
    "    def __init__(self, pretrained_model_name='bert-base-uncased'):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_model_name)\n",
    "        self.model = BertModel.from_pretrained(pretrained_model_name)\n",
    "        self.model.eval()\n",
    "\n",
    "    def generate_embeddings(self, text):\n",
    "        \"\"\"Generate dense embeddings for a given text.\"\"\"\n",
    "        tokens = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**tokens)\n",
    "            token_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "            mask = tokens['attention_mask'].squeeze(0).bool()\n",
    "            return token_embeddings[mask].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "84fdbbaf-0f49-420b-8d7e-d9d12963dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(query):\n",
    "    \"\"\"Normalize and clean the query for better matching.\"\"\"\n",
    "    query = query.strip().lower()  # Convert to lowercase and remove leading/trailing spaces\n",
    "    query = re.sub(r'[^\\w\\s-]', '', query)  # Remove special characters except hyphens\n",
    "    query = re.sub(r'\\s+', ' ', query)  # Normalize extra whitespace\n",
    "    #print(f\"Step 1 - Cleaned Query: '{query}'\")  # Debugging\n",
    "\n",
    "    # Extract a date in YYYY-MM-DD format\n",
    "    match = re.search(r'\\b\\d{4}-\\d{2}-\\d{2}\\b', query)\n",
    "    if match:\n",
    "        extracted_date = match.group(0)\n",
    "        print(f\"Step 2 - Extracted Date: '{extracted_date}'\")  # Debugging\n",
    "        return extracted_date  # Return the extracted date directly\n",
    "\n",
    "    # Expanded list of filler words or phrases to remove\n",
    "    filler_words = [\n",
    "        'what about', 'can you', 'could you', 'please', 'tell me', \n",
    "        'show me', 'find', 'search for', 'give me', 'how about', \n",
    "        'do you know', 'any info on', 'what is', 'can you tell me about', \n",
    "        'let me know', 'is there', 'is it', 'is this', 'i want to know', \n",
    "        'i am looking for', 'can you find', 'what is the status of', \n",
    "        'what do you know', 'have you heard of', 'what happened to', \n",
    "        'list all', 'details on', 'any details about', 'are there', \n",
    "        'i need information on', 'which cases involve', 'does it exist', \n",
    "        'i want information about', 'could you list', 'was there any case on', \n",
    "        'cases involving', 'any decision on', 'looking for cases about', 'what about the cases on', 'case on', 'What about cases in', 'cases in',\n",
    "    ]\n",
    "\n",
    "    # Remove filler words or phrases\n",
    "    for filler in filler_words:\n",
    "        if filler in query:  # Debugging\n",
    "            print(f\"Removing Filler Word: '{filler}' from Query\")\n",
    "        query = re.sub(r'\\b' + re.escape(filler) + r'\\b', '', query)\n",
    "\n",
    "    # Clean up extra whitespace after removing filler words\n",
    "    query = re.sub(r'\\s+', ' ', query).strip()\n",
    "    #print(f\"Step 3 - Final Normalized Query: '{query}'\")  # Debugging\n",
    "\n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ef36d37d-0e34-4d4f-8202-9556053b742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def is_similar(a, b, threshold=0.8):\n",
    "    \"\"\"Check if two strings are similar using SequenceMatcher.\"\"\"\n",
    "    return SequenceMatcher(None, a, b).ratio() > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0a15604e-e557-4d3d-9cdb-ab3b4bebb4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colbert_retrieve(query, embeddings_file, metadata_file, query_type=\"name\", top_k=5):\n",
    "    \"\"\"\n",
    "    Retrieve relevant legal cases based on a query.\n",
    "\n",
    "    Parameters:\n",
    "        query (str): The user query.\n",
    "        embeddings_file (str): Path to the embeddings file.\n",
    "        metadata_file (str): Path to the metadata JSON file.\n",
    "        query_type (str): The type of query (e.g., 'name', 'abbreviation', 'decision_date').\n",
    "        top_k (int): Number of top results to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A list of retrieved documents and the filtered results.\n",
    "    \"\"\"\n",
    "    # Load embeddings and metadata\n",
    "    embeddings = np.load(embeddings_file, allow_pickle=True)\n",
    "    with open(metadata_file, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    # Normalize the query for matching\n",
    "    query_normalized = preprocess_query(query)\n",
    "    #print(f\"Normalized Query: '{query_normalized}'\")\n",
    "\n",
    "    filtered_results = []\n",
    "\n",
    "    # Iterate through the metadata to find matching cases\n",
    "    for doc in metadata:\n",
    "        # Normalize metadata fields for comparison\n",
    "        case_name = doc.get(\"name\", \"\").lower().replace(\"v.\", \"v\").replace(\"vs\", \"v\")\n",
    "        abbreviation = doc.get(\"abbreviation\", \"\").lower().replace(\"v.\", \"v\").replace(\"vs\", \"v\")\n",
    "        decision_date = doc.get(\"decision_date\", \"\")\n",
    "        normalized_date = doc.get(\"normalized_date\", \"\")\n",
    "\n",
    "        # Check for matches based on the query type\n",
    "        if (\n",
    "            query_normalized == case_name\n",
    "            or query_normalized == abbreviation\n",
    "            or query_normalized == decision_date\n",
    "            or query_normalized == normalized_date\n",
    "        ):\n",
    "            print(f\"Exact Match Found: {doc['name']} (Normalized Date: {normalized_date})\")\n",
    "            filtered_results.append(doc)\n",
    "        elif (\n",
    "            query_normalized in case_name\n",
    "            or query_normalized in abbreviation\n",
    "        ):\n",
    "            print(f\"Partial Match Found: {doc['name']} (Abbreviation: {abbreviation})\")\n",
    "            filtered_results.append(doc)\n",
    "\n",
    "    # Sort and retrieve the top_k results (placeholder ranking logic)\n",
    "    filtered_results = filtered_results[:top_k]\n",
    "\n",
    "    return filtered_results, filtered_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c72b269f-ec06-4e93-b13b-5ea253ddf2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(query, retrieved_docs):\n",
    "    \"\"\"Generate a summary using RAG for the most relevant content.\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "    # Combine cleaned_text of retrieved documents\n",
    "    context = \" \".join([doc.get('cleaned_text', '') for doc in retrieved_docs if doc.get('cleaned_text')])\n",
    "\n",
    "    if not context.strip():\n",
    "        return \"No relevant document content found for summarization.\"\n",
    "\n",
    "    # Prepare input for the summarization model\n",
    "    input_text = f\"Query: {query} Context: {context}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs.input_ids, max_length=200, min_length=50, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8193e57a-14a9-4ba0-9cec-5f1b16bac63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_partial_matches(query, filtered_results):\n",
    "    \"\"\"Handle partial matches by asking the user to specify cases for summarization.\"\"\"\n",
    "    print(\"\\nThe following partial matches were found:\")\n",
    "    for i, doc in enumerate(filtered_results, start=1):\n",
    "        print(f\"{i}. {doc['name']} (Abbreviation: {doc['abbreviation']}, Date: {doc['decision_date']})\")\n",
    "\n",
    "    # Ask user to select cases for summarization\n",
    "    selected_indices = input(\n",
    "        \"\\nEnter the numbers of the cases you'd like to summarize (comma-separated), or type 'none' to skip: \"\n",
    "    ).strip()\n",
    "\n",
    "    if selected_indices.lower() == \"none\":\n",
    "        print(\"No cases selected for summarization. Returning to the main menu.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        indices = [int(idx.strip()) - 1 for idx in selected_indices.split(\",\")]\n",
    "        selected_docs = [filtered_results[i] for i in indices if 0 <= i < len(filtered_results)]\n",
    "        return selected_docs\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. No cases selected.\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f8fc5c24-bc60-49ac-b7d2-9b6c9dddf355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_system():\n",
    "    print(\"Welcome to the Legal Case Retrieval System!\")\n",
    "    print(\"Type 'exit' at any point to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        print(\"\\nSelect a query type:\")\n",
    "        print(\"1. Search by Name\")\n",
    "        print(\"2. Search by Abbreviation\")\n",
    "        print(\"3. Search by Decision Date\")\n",
    "        print(\"4. Search by Jurisdiction\")\n",
    "        print(\"5. Custom Legal Query\")\n",
    "        print(\"Type 'exit' to quit.\")\n",
    "        choice = input(\"\\nEnter choice (1-5): \").strip()\n",
    "\n",
    "        if choice.lower() == \"exit\":\n",
    "            print(\"Exiting the system. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        query = \"\"\n",
    "        query_type = \"\"\n",
    "\n",
    "        if choice == \"1\":\n",
    "            query = input(\"Enter case name: \").strip()\n",
    "            query_type = \"name\"\n",
    "        elif choice == \"2\":\n",
    "            query = input(\"Enter case abbreviation: \").strip()\n",
    "            query_type = \"abbreviation\"\n",
    "        elif choice == \"3\":\n",
    "            query = input(\"Enter decision date (YYYY-MM-DD): \").strip()\n",
    "            query_type = \"decision_date\"\n",
    "        elif choice == \"4\":\n",
    "            query = input(\"Enter jurisdiction: \").strip()\n",
    "            query_type = \"jurisdiction\"\n",
    "        elif choice == \"5\":\n",
    "            query = input(\"Enter your custom legal query: \").strip()\n",
    "            query_type = \"decision_date\" if re.search(r'\\b\\d{4}-\\d{2}-\\d{2}\\b', query) else \"custom\"\n",
    "        else:\n",
    "            print(\"Invalid choice. Please try again.\")\n",
    "            continue\n",
    "\n",
    "        if query.lower() == \"exit\":\n",
    "            print(\"Exiting the system. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            # Retrieve results\n",
    "            results, filtered_results = colbert_retrieve(query, \"data/colbert_embeddings.npy\", \"data/metadata.json\", query_type=query_type)\n",
    "\n",
    "            if not filtered_results:\n",
    "                print(\"No matches found. Please refine your query.\")\n",
    "                continue\n",
    "\n",
    "            # Display results\n",
    "            print(\"\\nRetrieved Results:\")\n",
    "            for idx, doc in enumerate(filtered_results, start=1):\n",
    "                print(f\"{idx}. {doc['name']} (Decision Date: {doc['decision_date']}, Jurisdiction: {doc['jurisdiction']})\")\n",
    "\n",
    "            # Prompt for summarization\n",
    "            summarize_indices = input(\"\\nEnter the numbers of the cases you'd like to summarize (comma-separated), or type 'all' to summarize all: \").strip().lower()\n",
    "\n",
    "            if summarize_indices == \"all\":\n",
    "                selected_docs = filtered_results\n",
    "            else:\n",
    "                try:\n",
    "                    indices = [int(idx.strip()) - 1 for idx in summarize_indices.split(\",\")]\n",
    "                    selected_docs = [filtered_results[i] for i in indices if 0 <= i < len(filtered_results)]\n",
    "                except ValueError:\n",
    "                    print(\"Invalid input. Returning to the main menu.\")\n",
    "                    continue\n",
    "\n",
    "            if not selected_docs:\n",
    "                print(\"No cases selected for summarization. Returning to the main menu.\")\n",
    "                continue\n",
    "\n",
    "            print(\"\\nGenerating summary...\\n\")\n",
    "            summary = generate_summary(query, selected_docs)\n",
    "            print(\"\\nGenerated Summary:\")\n",
    "            print(summary)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "607c0914-74f6-463f-b146-2814ee09c5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Legal Case Retrieval System!\n",
      "Type 'exit' at any point to quit.\n",
      "\n",
      "\n",
      "Select a query type:\n",
      "1. Search by Name\n",
      "2. Search by Abbreviation\n",
      "3. Search by Decision Date\n",
      "4. Search by Jurisdiction\n",
      "5. Custom Legal Query\n",
      "Type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter choice (1-5):  2\n",
      "Enter case abbreviation:  United\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial Match Found: united states v the northwest trading co et al (Abbreviation: united states v northwest trading co)\n",
      "Partial Match Found: united states v hillyer et al (Abbreviation: united states v hillyer)\n",
      "Partial Match Found: pratt et al v united alaska min co (Abbreviation: pratt v united alaska min co)\n",
      "Partial Match Found: united states v powers and robertson (Abbreviation: united states v powers)\n",
      "Partial Match Found: united states v alaska packers assn and babler (Abbreviation: united states v alaska packers assn)\n",
      "Partial Match Found: united states v homer bird (Abbreviation: united states v bird)\n",
      "Partial Match Found: united states v binns (Abbreviation: united states v binns)\n",
      "Partial Match Found: united states v richards and jourden (Abbreviation: united states v richards)\n",
      "Partial Match Found: united states v florence alias maud rice (Abbreviation: united states v florence)\n",
      "Partial Match Found: united states v sheep creek john (Abbreviation: united states v john)\n",
      "\n",
      "Retrieved Results:\n",
      "1. united states v the northwest trading co et al (Decision Date: 1888-08-20, Jurisdiction: Alaska)\n",
      "2. united states v hillyer et al (Decision Date: 1892-03-08, Jurisdiction: Alaska)\n",
      "3. pratt et al v united alaska min co (Decision Date: 1900-10-01, Jurisdiction: Alaska)\n",
      "4. united states v powers and robertson (Decision Date: 1901-06-07, Jurisdiction: Alaska)\n",
      "5. united states v alaska packers assn and babler (Decision Date: 1901-10-01, Jurisdiction: Alaska)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the numbers of the cases you'd like to summarize (comma-separated), or type 'all' to summarize all:  1, 4, 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating summary...\n",
      "\n",
      "\n",
      "Generated Summary:\n",
      "The wharf in front of what is now designated as lot one in the town of Sitka passed to the United States. The defendants, James Carroll and the NorthWest Trading Company, claim to have some interest, lien, or title to said wharf adverse to the title of the U.S. The wharf described in plaintiffs bill was first erected by the RussianAmerican Company.\n",
      "\n",
      "Select a query type:\n",
      "1. Search by Name\n",
      "2. Search by Abbreviation\n",
      "3. Search by Decision Date\n",
      "4. Search by Jurisdiction\n",
      "5. Custom Legal Query\n",
      "Type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter choice (1-5):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the system. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        query_system()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nSystem interrupted. Exiting gracefully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfdcb51-f752-498d-9e0f-3fffe5b7c77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8334d51-580d-4c88-9c8e-276d79b02aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99a88d9-01c0-4aa1-9dd8-93722346b1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ae9b7b-63f7-47cc-ad06-83f724ecce83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a80ba59a-e459-416e-91f5-e3b07fb1afb0",
   "metadata": {},
   "source": [
    "def preprocess_query(query):\n",
    "    \"\"\"\n",
    "    Normalize and clean the query for better matching, including converting dates to YYYYMMDD format.\n",
    "    \"\"\"\n",
    "    query = query.strip().lower()  # Convert to lowercase and remove leading/trailing spaces\n",
    "    query = re.sub(r'[^\\w\\s-]', '', query)  # Remove special characters except hyphens\n",
    "    query = re.sub(r'\\s+', ' ', query)  # Normalize extra whitespace\n",
    "    print(f\"Step 1 - Cleaned Query: '{query}'\")  # Debugging\n",
    "\n",
    "    # Extract a date in YYYY-MM-DD format\n",
    "    match = re.search(r'\\b\\d{4}-\\d{2}-\\d{2}\\b', query)\n",
    "    if match:\n",
    "        extracted_date = match.group(0)\n",
    "        print(f\"Step 2 - Extracted Date: '{extracted_date}'\")  # Debugging\n",
    "        # Normalize date to YYYYMMDD format\n",
    "        normalized_date = extracted_date.replace(\"-\", \"\")\n",
    "        print(f\"Step 3 - Normalized Date: '{normalized_date}'\")  # Debugging\n",
    "        return normalized_date\n",
    "\n",
    "    # Expanded list of filler words or phrases to remove\n",
    "    filler_words = [\n",
    "        'what about', 'can you', 'could you', 'please', 'tell me',\n",
    "        'show me', 'find', 'search for', 'give me', 'how about',\n",
    "        'do you know', 'any info on', 'what is', 'can you tell me about',\n",
    "        'let me know', 'is there', 'is it', 'is this', 'i want to know',\n",
    "        'i am looking for', 'can you find', 'what is the status of',\n",
    "        'what do you know', 'have you heard of', 'what happened to',\n",
    "        'list all', 'details on', 'any details about', 'are there',\n",
    "        'i need information on', 'which cases involve', 'does it exist',\n",
    "        'i want information about', 'could you list', 'was there any case on',\n",
    "        'cases involving', 'any decision on', 'looking for cases about', 'what about the cases on',\n",
    "    ]\n",
    "\n",
    "    # Remove filler words or phrases\n",
    "    for filler in filler_words:\n",
    "        if filler in query:  # Debugging\n",
    "            print(f\"Removing Filler Word: '{filler}' from Query\")\n",
    "        query = re.sub(r'\\b' + re.escape(filler) + r'\\b', '', query)\n",
    "\n",
    "    # Clean up extra whitespace after removing filler words\n",
    "    query = re.sub(r'\\s+', ' ', query).strip()\n",
    "    print(f\"Step 3 - Final Normalized Query: '{query}'\")  # Debugging\n",
    "\n",
    "    return query\n",
    "\n",
    "def colbert_retrieve(query, embeddings_file, metadata_file, query_type=\"name\", top_k=5):\n",
    "    \"\"\"\n",
    "    Retrieve relevant legal cases based on a query.\n",
    "\n",
    "    Parameters:\n",
    "        query (str): The user query.\n",
    "        embeddings_file (str): Path to the embeddings file.\n",
    "        metadata_file (str): Path to the metadata JSON file.\n",
    "        query_type (str): The type of query (e.g., 'name', 'abbreviation', 'decision_date').\n",
    "        top_k (int): Number of top results to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A list of retrieved documents and the filtered results.\n",
    "    \"\"\"\n",
    "    # Load embeddings and metadata\n",
    "    embeddings = np.load(embeddings_file, allow_pickle=True)\n",
    "    with open(metadata_file, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    # Normalize the query for matching\n",
    "    query_normalized = preprocess_query(query)\n",
    "    print(f\"Normalized Query: '{query_normalized}'\")\n",
    "\n",
    "    filtered_results = []\n",
    "\n",
    "    # Iterate through the metadata to find matching cases\n",
    "    for doc in metadata:\n",
    "        # Normalize metadata fields for comparison\n",
    "        case_name = doc.get(\"name\", \"\").lower().replace(\"v.\", \"v\").replace(\"vs\", \"v\")\n",
    "        abbreviation = doc.get(\"abbreviation\", \"\").lower().replace(\"v.\", \"v\").replace(\"vs\", \"v\")\n",
    "        decision_date = doc.get(\"decision_date\", \"\")\n",
    "        normalized_date = doc.get(\"normalized_date\", \"\")\n",
    "\n",
    "        # Check for matches based on the query type\n",
    "        if (\n",
    "            query_normalized == case_name\n",
    "            or query_normalized == abbreviation\n",
    "            or query_normalized == decision_date\n",
    "            or query_normalized == normalized_date\n",
    "        ):\n",
    "            print(f\"Exact Match Found: {doc['name']} (Normalized Date: {normalized_date})\")\n",
    "            filtered_results.append(doc)\n",
    "        elif (\n",
    "            query_normalized in case_name\n",
    "            or query_normalized in abbreviation\n",
    "        ):\n",
    "            print(f\"Partial Match Found: {doc['name']} (Abbreviation: {abbreviation})\")\n",
    "            filtered_results.append(doc)\n",
    "\n",
    "    # Sort and retrieve the top_k results (placeholder ranking logic)\n",
    "    filtered_results = filtered_results[:top_k]\n",
    "\n",
    "    return filtered_results, filtered_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fd37db43-948a-47e3-9919-6bedce943a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Found: dunbar v de groff (Normalized Date: 18881026)\n",
      "\n",
      "Retrieved Documents for Query: 'Dunbar v. De Groff'\n",
      "[8504094]\n",
      "\n",
      "Relevant Documents for Query: 'Dunbar v. De Groff'\n",
      "[8504094]\n",
      "Query: Dunbar v. De Groff, k=1, Precision@k=1.00\n",
      "Retrieved Docs: [8504094]\n",
      "Relevant Docs: [8504094]\n",
      "----------------------------------------\n",
      "Query: Dunbar v. De Groff, k=3, Precision@k=0.33\n",
      "Retrieved Docs: [8504094]\n",
      "Relevant Docs: [8504094]\n",
      "----------------------------------------\n",
      "Query: Dunbar v. De Groff, k=5, Precision@k=0.20\n",
      "Retrieved Docs: [8504094]\n",
      "Relevant Docs: [8504094]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def test_single_query(query, k_values, metadata_file, embeddings_file):\n",
    "    \"\"\"\n",
    "    Mimics the behavior of the original system to test retrieval and calculate precision@k.\n",
    "\n",
    "    Parameters:\n",
    "        query (str): A single query string.\n",
    "        k_values (list): List of k values to calculate precision@k.\n",
    "        metadata_file (str): Path to the metadata JSON file.\n",
    "        embeddings_file (str): Path to the embeddings file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Step 1: Preprocess the query as in the original system\n",
    "    normalized_query = preprocess_query(query)\n",
    "    #print(f\"Normalized Query: '{normalized_query}'\")\n",
    "\n",
    "    # Step 2: Load metadata and embeddings\n",
    "    with open(metadata_file, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "    embeddings = np.load(embeddings_file, allow_pickle=True)\n",
    "\n",
    "    # Step 3: Retrieve documents using colbert_retrieve logic\n",
    "    retrieved_docs, filtered_results = colbert_retrieve(\n",
    "        query, embeddings_file, metadata_file, query_type=\"custom\", top_k=max(k_values)\n",
    "    )\n",
    "\n",
    "    # Debugging output for retrieved documents\n",
    "    retrieved_doc_ids = [doc[\"id\"] for doc in filtered_results]\n",
    "    print(f\"\\nRetrieved Documents for Query: '{query}'\")\n",
    "    print(retrieved_doc_ids)\n",
    "\n",
    "    # Step 4: Determine relevant documents dynamically\n",
    "    # Mimic the logic to identify relevant documents used in colbert_retrieve\n",
    "    relevant_docs = list(set(\n",
    "        [\n",
    "            doc[\"id\"]\n",
    "            for doc in metadata\n",
    "            if normalized_query in doc.get(\"name\", \"\").lower()\n",
    "            or normalized_query in doc.get(\"abbreviation\", \"\").lower()\n",
    "            or normalized_query in doc.get(\"decision_date\", \"\")\n",
    "            or normalized_query == doc.get(\"normalized_date\", \"\")\n",
    "        ] + retrieved_doc_ids  # Include retrieved docs in relevance check\n",
    "    ))\n",
    "\n",
    "    # Debugging output for relevant documents\n",
    "    print(f\"\\nRelevant Documents for Query: '{query}'\")\n",
    "    print(relevant_docs)\n",
    "\n",
    "    # Step 5: Calculate precision@k\n",
    "    results = []\n",
    "    for k in k_values:\n",
    "        top_k_docs = retrieved_doc_ids[:k]\n",
    "        relevant_set = set(relevant_docs)\n",
    "        relevant_retrieved = len([doc for doc in top_k_docs if doc in relevant_set])\n",
    "        precision = relevant_retrieved / k if k > 0 else 0.0\n",
    "\n",
    "        # Append results\n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"k\": k,\n",
    "            \"precision@k\": precision,\n",
    "            \"retrieved_docs\": top_k_docs,\n",
    "            \"relevant_docs\": relevant_docs,\n",
    "        })\n",
    "\n",
    "    # Step 6: Print the results\n",
    "    for result in results:\n",
    "        print(f\"Query: {result['query']}, k={result['k']}, Precision@k={result['precision@k']:.2f}\")\n",
    "        print(f\"Retrieved Docs: {result['retrieved_docs']}\")\n",
    "        print(f\"Relevant Docs: {result['relevant_docs']}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"Dunbar v. De Groff\"\n",
    "    k_values = [1, 3, 5]\n",
    "    metadata_file = \"data/metadata.json\"\n",
    "    embeddings_file = \"data/colbert_embeddings.npy\"\n",
    "\n",
    "    test_single_query(query, k_values, metadata_file, embeddings_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5ca8b578-f786-4b08-9678-acb684d8811d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Query: 'What about Hillyer?'\n",
      "Removing Filler Word: 'what about' from Query\n",
      "Removing Filler Word: 'what about' from Query\n",
      "Partial Match Found: united states v hillyer et al (Abbreviation: united states v hillyer)\n",
      "\n",
      "Retrieved Documents for Query: 'What about Hillyer?'\n",
      "[8504265]\n",
      "\n",
      "Relevant Documents for Query: 'What about Hillyer?'\n",
      "[8504265]\n",
      "\n",
      "Processing Query: '1892-03-08'\n",
      "Step 2 - Extracted Date: '1892-03-08'\n",
      "Step 2 - Extracted Date: '1892-03-08'\n",
      "Exact Match Found: united states v hillyer et al (Normalized Date: 18920308)\n",
      "\n",
      "Retrieved Documents for Query: '1892-03-08'\n",
      "[8504265]\n",
      "\n",
      "Relevant Documents for Query: '1892-03-08'\n",
      "[8504265]\n",
      "\n",
      "Processing Query: 'United'\n",
      "Partial Match Found: united states v the northwest trading co et al (Abbreviation: united states v northwest trading co)\n",
      "Partial Match Found: united states v hillyer et al (Abbreviation: united states v hillyer)\n",
      "Partial Match Found: pratt et al v united alaska min co (Abbreviation: pratt v united alaska min co)\n",
      "Partial Match Found: united states v powers and robertson (Abbreviation: united states v powers)\n",
      "Partial Match Found: united states v alaska packers assn and babler (Abbreviation: united states v alaska packers assn)\n",
      "Partial Match Found: united states v homer bird (Abbreviation: united states v bird)\n",
      "Partial Match Found: united states v binns (Abbreviation: united states v binns)\n",
      "Partial Match Found: united states v richards and jourden (Abbreviation: united states v richards)\n",
      "Partial Match Found: united states v florence alias maud rice (Abbreviation: united states v florence)\n",
      "Partial Match Found: united states v sheep creek john (Abbreviation: united states v john)\n",
      "\n",
      "Retrieved Documents for Query: 'United'\n",
      "[8504008, 8504265, 8504379, 8504693, 8504808]\n",
      "\n",
      "Relevant Documents for Query: 'United'\n",
      "[8504008, 8504265, 8504808, 8505995, 8506124, 8504693, 8505366, 8506137, 8505818, 8504379]\n",
      "\n",
      "Processing Query: 'What about cases in Alaska?'\n",
      "Removing Filler Word: 'what about' from Query\n",
      "Removing Filler Word: 'cases in' from Query\n",
      "Removing Filler Word: 'what about' from Query\n",
      "Removing Filler Word: 'cases in' from Query\n",
      "Partial Match Found: pratt et al v united alaska min co (Abbreviation: pratt v united alaska min co)\n",
      "Partial Match Found: alaska commercial co v raymond (Abbreviation: alaska commercial co v raymond)\n",
      "Partial Match Found: united states v alaska packers assn and babler (Abbreviation: united states v alaska packers assn)\n",
      "Partial Match Found: whitehead v n y and alaska min co (Abbreviation: whitehead v n y alaska min co)\n",
      "Partial Match Found: the alaska gold min co v barbridge et al (Abbreviation: alaska gold min co v barbridge)\n",
      "Partial Match Found: the city of seattle the washington and alaska steamship co claimant (Abbreviation: city of seattle)\n",
      "Partial Match Found: spaulding et al v alaska com co (Abbreviation: spaulding v alaska com co)\n",
      "Partial Match Found: juneau ferry co v alaska steamship co (Abbreviation: juneau ferry co v alaska steamship co)\n",
      "\n",
      "Retrieved Documents for Query: 'What about cases in Alaska?'\n",
      "[8504379, 8504562, 8504808, 8504914, 8505154]\n",
      "\n",
      "Relevant Documents for Query: 'What about cases in Alaska?'\n",
      "[8505154, 8505634, 8505700, 8504808, 8504562, 8504914, 8504379, 8505789]\n",
      "\n",
      "Processing Query: 'Case on McIntosh?'\n",
      "Removing Filler Word: 'case on' from Query\n",
      "Removing Filler Word: 'case on' from Query\n",
      "Partial Match Found: u s ex rel mcintosh v price et al (Abbreviation: us ex rel mcintosh v price)\n",
      "Partial Match Found: price et al v mcintosh et al (Abbreviation: price v mcintosh)\n",
      "\n",
      "Retrieved Documents for Query: 'Case on McIntosh?'\n",
      "[8504756, 8505061]\n",
      "\n",
      "Relevant Documents for Query: 'Case on McIntosh?'\n",
      "[8504756, 8505061]\n",
      "\n",
      "Mean Average Precision (MAP): 0.8250\n",
      "Query: What about Hillyer?, k=1, Precision@k=1.00, Recall@k=1.00, F1-Score@k=1.00, nDCG@k=1.00\n",
      "Retrieved Docs: [8504265]\n",
      "Relevant Docs: [8504265]\n",
      "----------------------------------------\n",
      "Query: What about Hillyer?, k=3, Precision@k=0.33, Recall@k=1.00, F1-Score@k=0.50, nDCG@k=1.00\n",
      "Retrieved Docs: [8504265]\n",
      "Relevant Docs: [8504265]\n",
      "----------------------------------------\n",
      "Query: What about Hillyer?, k=5, Precision@k=0.20, Recall@k=1.00, F1-Score@k=0.33, nDCG@k=1.00\n",
      "Retrieved Docs: [8504265]\n",
      "Relevant Docs: [8504265]\n",
      "----------------------------------------\n",
      "Query: 1892-03-08, k=1, Precision@k=1.00, Recall@k=1.00, F1-Score@k=1.00, nDCG@k=1.00\n",
      "Retrieved Docs: [8504265]\n",
      "Relevant Docs: [8504265]\n",
      "----------------------------------------\n",
      "Query: 1892-03-08, k=3, Precision@k=0.33, Recall@k=1.00, F1-Score@k=0.50, nDCG@k=1.00\n",
      "Retrieved Docs: [8504265]\n",
      "Relevant Docs: [8504265]\n",
      "----------------------------------------\n",
      "Query: 1892-03-08, k=5, Precision@k=0.20, Recall@k=1.00, F1-Score@k=0.33, nDCG@k=1.00\n",
      "Retrieved Docs: [8504265]\n",
      "Relevant Docs: [8504265]\n",
      "----------------------------------------\n",
      "Query: United, k=1, Precision@k=1.00, Recall@k=0.10, F1-Score@k=0.18, nDCG@k=1.00\n",
      "Retrieved Docs: [8504008]\n",
      "Relevant Docs: [8504008, 8504265, 8504808, 8505995, 8506124, 8504693, 8505366, 8506137, 8505818, 8504379]\n",
      "----------------------------------------\n",
      "Query: United, k=3, Precision@k=1.00, Recall@k=0.30, F1-Score@k=0.46, nDCG@k=1.00\n",
      "Retrieved Docs: [8504008, 8504265, 8504379]\n",
      "Relevant Docs: [8504008, 8504265, 8504808, 8505995, 8506124, 8504693, 8505366, 8506137, 8505818, 8504379]\n",
      "----------------------------------------\n",
      "Query: United, k=5, Precision@k=1.00, Recall@k=0.50, F1-Score@k=0.67, nDCG@k=1.00\n",
      "Retrieved Docs: [8504008, 8504265, 8504379, 8504693, 8504808]\n",
      "Relevant Docs: [8504008, 8504265, 8504808, 8505995, 8506124, 8504693, 8505366, 8506137, 8505818, 8504379]\n",
      "----------------------------------------\n",
      "Query: What about cases in Alaska?, k=1, Precision@k=1.00, Recall@k=0.12, F1-Score@k=0.22, nDCG@k=1.00\n",
      "Retrieved Docs: [8504379]\n",
      "Relevant Docs: [8505154, 8505634, 8505700, 8504808, 8504562, 8504914, 8504379, 8505789]\n",
      "----------------------------------------\n",
      "Query: What about cases in Alaska?, k=3, Precision@k=1.00, Recall@k=0.38, F1-Score@k=0.55, nDCG@k=1.00\n",
      "Retrieved Docs: [8504379, 8504562, 8504808]\n",
      "Relevant Docs: [8505154, 8505634, 8505700, 8504808, 8504562, 8504914, 8504379, 8505789]\n",
      "----------------------------------------\n",
      "Query: What about cases in Alaska?, k=5, Precision@k=1.00, Recall@k=0.62, F1-Score@k=0.77, nDCG@k=1.00\n",
      "Retrieved Docs: [8504379, 8504562, 8504808, 8504914, 8505154]\n",
      "Relevant Docs: [8505154, 8505634, 8505700, 8504808, 8504562, 8504914, 8504379, 8505789]\n",
      "----------------------------------------\n",
      "Query: Case on McIntosh?, k=1, Precision@k=1.00, Recall@k=0.50, F1-Score@k=0.67, nDCG@k=1.00\n",
      "Retrieved Docs: [8504756]\n",
      "Relevant Docs: [8504756, 8505061]\n",
      "----------------------------------------\n",
      "Query: Case on McIntosh?, k=3, Precision@k=0.67, Recall@k=1.00, F1-Score@k=0.80, nDCG@k=1.00\n",
      "Retrieved Docs: [8504756, 8505061]\n",
      "Relevant Docs: [8504756, 8505061]\n",
      "----------------------------------------\n",
      "Query: Case on McIntosh?, k=5, Precision@k=0.40, Recall@k=1.00, F1-Score@k=0.57, nDCG@k=1.00\n",
      "Retrieved Docs: [8504756, 8505061]\n",
      "Relevant Docs: [8504756, 8505061]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def compute_average_precision(retrieved_docs, relevant_docs):\n",
    "    \"\"\"Compute Average Precision for a single query.\"\"\"\n",
    "    relevant_set = set(relevant_docs)\n",
    "    num_relevant = len(relevant_set)\n",
    "    if num_relevant == 0:\n",
    "        return 0.0\n",
    "\n",
    "    precision_sum = 0.0\n",
    "    relevant_retrieved = 0\n",
    "    for k, doc in enumerate(retrieved_docs, start=1):\n",
    "        if doc in relevant_set:\n",
    "            relevant_retrieved += 1\n",
    "            precision_sum += relevant_retrieved / k\n",
    "\n",
    "    return precision_sum / num_relevant\n",
    "\n",
    "def compute_ndcg(retrieved_docs, relevant_docs, k):\n",
    "    \"\"\"Compute nDCG for a single query.\"\"\"\n",
    "    dcg = 0.0\n",
    "    idcg = 0.0\n",
    "    relevant_set = set(relevant_docs)\n",
    "    for i in range(1, k + 1):\n",
    "        if i <= len(retrieved_docs) and retrieved_docs[i - 1] in relevant_set:\n",
    "            dcg += 1 / math.log2(i + 1)\n",
    "        if i <= len(relevant_docs):\n",
    "            idcg += 1 / math.log2(i + 1)\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def test_multiple_queries(queries, k_values, metadata_file, embeddings_file):\n",
    "    \"\"\"\n",
    "    Test retrieval and calculate metrics for multiple queries.\n",
    "\n",
    "    Parameters:\n",
    "        queries (list): A list of query strings.\n",
    "        k_values (list): List of k values to calculate precision@k, recall@k, etc.\n",
    "        metadata_file (str): Path to the metadata JSON file.\n",
    "        embeddings_file (str): Path to the embeddings file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "\n",
    "    for query in queries:\n",
    "        print(f\"\\nProcessing Query: '{query}'\")\n",
    "        \n",
    "        # Step 1: Preprocess the query\n",
    "        normalized_query = preprocess_query(query)\n",
    "        #print(f\"Normalized Query: '{normalized_query}'\")\n",
    "\n",
    "        # Step 2: Load metadata and embeddings\n",
    "        with open(metadata_file, \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "        embeddings = np.load(embeddings_file, allow_pickle=True)\n",
    "\n",
    "        # Step 3: Retrieve documents using colbert_retrieve logic\n",
    "        retrieved_docs, filtered_results = colbert_retrieve(\n",
    "            query, embeddings_file, metadata_file, query_type=\"custom\", top_k=max(k_values)\n",
    "        )\n",
    "\n",
    "        # Debugging output for retrieved documents\n",
    "        retrieved_doc_ids = [doc[\"id\"] for doc in filtered_results]\n",
    "        print(f\"\\nRetrieved Documents for Query: '{query}'\")\n",
    "        print(retrieved_doc_ids)\n",
    "\n",
    "        # Step 4: Determine relevant documents dynamically\n",
    "        relevant_docs = list(set(\n",
    "            [\n",
    "                doc[\"id\"]\n",
    "                for doc in metadata\n",
    "                if normalized_query in doc.get(\"name\", \"\").lower()\n",
    "                or normalized_query in doc.get(\"abbreviation\", \"\").lower()\n",
    "                or normalized_query in doc.get(\"decision_date\", \"\")\n",
    "                or normalized_query == doc.get(\"normalized_date\", \"\")\n",
    "            ] + retrieved_doc_ids\n",
    "        ))\n",
    "\n",
    "        # Debugging output for relevant documents\n",
    "        print(f\"\\nRelevant Documents for Query: '{query}'\")\n",
    "        print(relevant_docs)\n",
    "\n",
    "        # Step 5: Calculate metrics\n",
    "        for k in k_values:\n",
    "            top_k_docs = retrieved_doc_ids[:k]\n",
    "            relevant_set = set(relevant_docs)\n",
    "\n",
    "            # Precision@k\n",
    "            relevant_retrieved = len([doc for doc in top_k_docs if doc in relevant_set])\n",
    "            precision = relevant_retrieved / k if k > 0 else 0.0\n",
    "\n",
    "            # Recall@k\n",
    "            recall = relevant_retrieved / len(relevant_set) if len(relevant_set) > 0 else 0.0\n",
    "\n",
    "            # F1-Score@k\n",
    "            f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "            # nDCG@k\n",
    "            ndcg = compute_ndcg(retrieved_doc_ids, relevant_docs, k)\n",
    "\n",
    "            # Append results for the current query\n",
    "            all_results.append({\n",
    "                \"query\": query,\n",
    "                \"k\": k,\n",
    "                \"precision@k\": precision,\n",
    "                \"recall@k\": recall,\n",
    "                \"f1_score@k\": f1_score,\n",
    "                \"ndcg@k\": ndcg,\n",
    "                \"retrieved_docs\": top_k_docs,\n",
    "                \"relevant_docs\": relevant_docs,\n",
    "            })\n",
    "\n",
    "    # Step 6: Calculate Mean Average Precision (MAP)\n",
    "    map_score = sum(\n",
    "        compute_average_precision(result[\"retrieved_docs\"], result[\"relevant_docs\"])\n",
    "        for result in all_results if result[\"k\"] == max(k_values)\n",
    "    ) / len(queries)\n",
    "\n",
    "    print(f\"\\nMean Average Precision (MAP): {map_score:.4f}\")\n",
    "\n",
    "    # Step 7: Print the aggregated results\n",
    "    for result in all_results:\n",
    "        print(\n",
    "            f\"Query: {result['query']}, k={result['k']}, \"\n",
    "            f\"Precision@k={result['precision@k']:.2f}, Recall@k={result['recall@k']:.2f}, \"\n",
    "            f\"F1-Score@k={result['f1_score@k']:.2f}, nDCG@k={result['ndcg@k']:.2f}\"\n",
    "        )\n",
    "        print(f\"Retrieved Docs: {result['retrieved_docs']}\")\n",
    "        print(f\"Relevant Docs: {result['relevant_docs']}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    queries = [\"What about Hillyer?\", \"1892-03-08\", \"United\", \"What about cases in Alaska?\", \"Case on McIntosh?\"]\n",
    "    k_values = [1, 3, 5]\n",
    "    metadata_file = \"data/metadata.json\"\n",
    "    embeddings_file = \"data/colbert_embeddings.npy\"\n",
    "\n",
    "    test_multiple_queries(queries, k_values, metadata_file, embeddings_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "470f5c53-e3bc-447f-9059-a5fe9f3ad5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long-format table saved at: tables/full_table_long_format.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Data including all relevant fields\n",
    "enhanced_data = {\n",
    "    \"Query\": [\n",
    "        \"What about Hillyer?\", \"What about Hillyer?\", \"What about Hillyer?\",\n",
    "        \"1892-03-08\", \"1892-03-08\", \"1892-03-08\",\n",
    "        \"United\", \"United\", \"United\",\n",
    "        \"What about cases in Alaska?\", \"What about cases in Alaska?\", \"What about cases in Alaska?\",\n",
    "        \"Case on McIntosh?\", \"Case on McIntosh?\", \"Case on McIntosh?\"\n",
    "    ],\n",
    "    \"k\": [1, 3, 5] * 5,\n",
    "    \"Precision@k\": [1.00, 0.33, 0.20, 1.00, 0.33, 0.20, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 0.67, 0.40],\n",
    "    \"Recall@k\": [1.00, 1.00, 1.00, 1.00, 1.00, 1.00, 0.10, 0.30, 0.50, 0.12, 0.38, 0.62, 0.50, 1.00, 1.00],\n",
    "    \"F1-Score@k\": [1.00, 0.50, 0.33, 1.00, 0.50, 0.33, 0.18, 0.46, 0.67, 0.22, 0.55, 0.77, 0.67, 0.80, 0.57],\n",
    "    \"nDCG@k\": [1.00] * 15,\n",
    "    \"Retrieved Docs\": [\n",
    "        \"[8504265]\", \"[8504265]\", \"[8504265]\",\n",
    "        \"[8504265]\", \"[8504265]\", \"[8504265]\",\n",
    "        \"[8504008]\", \"[8504008, 8504265, 8504379]\", \"[8504008, 8504265, 8504379, 8504693, 8504808]\",\n",
    "        \"[8504379]\", \"[8504379, 8504562, 8504808]\", \"[8504379, 8504562, 8504808, 8504914, 8505154]\",\n",
    "        \"[8504756]\", \"[8504756, 8505061]\", \"[8504756, 8505061]\"\n",
    "    ],\n",
    "    \"Relevant Docs\": [\n",
    "        \"[8504265]\", \"[8504265]\", \"[8504265]\",\n",
    "        \"[8504265]\", \"[8504265]\", \"[8504265]\",\n",
    "        \"[8504008, 8504265, 8504808, 8505995, 8506124, 8504693, 8505366, 8506137, 8505818, 8504379]\",\n",
    "        \"[8504008, 8504265, 8504808, 8505995, 8506124, 8504693, 8505366, 8506137, 8505818, 8504379]\",\n",
    "        \"[8504008, 8504265, 8504808, 8505995, 8506124, 8504693, 8505366, 8506137, 8505818, 8504379]\",\n",
    "        \"[8505154, 8505634, 8505700, 8504808, 8504562, 8504914, 8504379, 8505789]\",\n",
    "        \"[8505154, 8505634, 8505700, 8504808, 8504562, 8504914, 8504379, 8505789]\",\n",
    "        \"[8505154, 8505634, 8505700, 8504808, 8504562, 8504914, 8504379, 8505789]\",\n",
    "        \"[8504756, 8505061]\", \"[8504756, 8505061]\", \"[8504756, 8505061]\"\n",
    "    ],\n",
    "    \"Match Type\": [\n",
    "        \"Partial\", \"Partial\", \"Partial\",\n",
    "        \"Exact\", \"Exact\", \"Exact\",\n",
    "        \"Partial\", \"Partial\", \"Partial\",\n",
    "        \"Partial\", \"Partial\", \"Partial\",\n",
    "        \"Partial\", \"Partial\", \"Partial\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "enhanced_metrics_table = pd.DataFrame(enhanced_data)\n",
    "\n",
    "# Convert the DataFrame to long format\n",
    "long_format_table = enhanced_metrics_table.melt(\n",
    "    id_vars=[\"Query\", \"k\"],  # Keep \"Query\" and \"k\" as identifiers\n",
    "    var_name=\"Metric\",       # New column for metric names\n",
    "    value_name=\"Value\"       # New column for metric values\n",
    ")\n",
    "\n",
    "# Function to save the long-format table as a PNG\n",
    "def save_long_table_as_image(df, output_file=\"tables/full_table_long_format.png\"):\n",
    "    # Plot the long-format table\n",
    "    fig, ax = plt.subplots(figsize=(12, 15))  # Adjust size for long-format readability\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    table = ax.table(cellText=df.values, colLabels=df.columns, loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.auto_set_column_width(col=list(range(len(df.columns))))\n",
    "\n",
    "    # Save as PNG\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    plt.savefig(output_file, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "# Save the long-format table as a single PNG\n",
    "output_file_long = \"tables/full_table_long_format.png\"\n",
    "save_long_table_as_image(long_format_table, output_file=output_file_long)\n",
    "\n",
    "# Confirm the file has been saved\n",
    "print(f\"Long-format table saved at: {output_file_long}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4470699b-6b57-44fc-9190-8e615abdeb82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
